Namespace(arch='DN_X', config='../models/architectures/configs/DN7_DA.yaml', dengine=True, refit_dengine=True, dataset_dir='../dataset/StanfordDogs/', data_name='test', mode='test', resume='../results/models/dn7da_stanfordogs_5_5_k3_epoch_27.pth.tar', epochs=1, ngpu=1, print_freq=100, outf='../results/DN_X_test_DN4_5_Way_5_Shot_K3')=> loaded checkpoint '../results/models/dn7da_stanfordogs_5_5_k3_epoch_27.pth.tar' (epoch 27)
DN_X(
  (BACKBONE): SevenLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
      (14): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (15): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (16): LeakyReLU(negative_slope=0.2, inplace=True)
      (17): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (18): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (19): LeakyReLU(negative_slope=0.2, inplace=True)
      (20): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (21): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (22): LeakyReLU(negative_slope=0.2, inplace=True)
      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (criterion): CrossEntropyLoss()
  )
  (DE): RandomForestHead()
)
Trainset: 10000
Valset: 600
Testset: 600
===================================== Round 0 =====================================
Testset: 600-------------0
Test-(27): [100/600]	Time 0.168 (0.167)	Loss 1.125 (1.214)	Prec@1 78.0 (69.089111328125)

Test-(27): [200/600]	Time 0.179 (0.160)	Loss 1.245 (1.229)	Prec@1 66.0 (67.5721435546875)

Test-(27): [300/600]	Time 0.194 (0.159)	Loss 1.285 (1.232)	Prec@1 62.0 (67.2956771850586)

Test-(27): [400/600]	Time 0.129 (0.158)	Loss 1.085 (1.232)	Prec@1 82.0 (67.30673217773438)

Test-(27): [500/600]	Time 0.138 (0.156)	Loss 1.165 (1.232)	Prec@1 74.0 (67.28543090820312)
 * Prec@1 67.453 Best_prec1 0.000Test accuracy= 67.45333099365234 h= 0.8028467297554016
===================================== Round 1 =====================================
Testset: 600-------------1
Test-(27): [100/600]	Time 0.149 (0.166)	Loss 1.205 (1.229)	Prec@1 70.0 (67.60395812988281)

Test-(27): [200/600]	Time 0.108 (0.157)	Loss 1.305 (1.234)	Prec@1 60.0 (67.09452819824219)

Test-(27): [300/600]	Time 0.164 (0.156)	Loss 1.245 (1.231)	Prec@1 66.0 (67.35547637939453)

Test-(27): [400/600]	Time 0.169 (0.154)	Loss 1.105 (1.234)	Prec@1 80.0 (67.07231903076172)

Test-(27): [500/600]	Time 0.109 (0.154)	Loss 1.225 (1.234)	Prec@1 68.0 (67.09381103515625)
 * Prec@1 66.987 Best_prec1 67.453Test accuracy= 66.98666381835938 h= 0.8313942551612854
===================================== Round 2 =====================================
Testset: 600-------------2
Test-(27): [100/600]	Time 0.158 (0.163)	Loss 1.225 (1.214)	Prec@1 68.0 (69.06930541992188)

Test-(27): [200/600]	Time 0.168 (0.159)	Loss 1.105 (1.218)	Prec@1 80.0 (68.70646667480469)

Test-(27): [300/600]	Time 0.176 (0.156)	Loss 1.345 (1.223)	Prec@1 56.0 (68.13953399658203)

Test-(27): [400/600]	Time 0.142 (0.155)	Loss 1.265 (1.228)	Prec@1 64.0 (67.66084289550781)
