Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (criterion): CrossEntropyLoss()
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=28224, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 10000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Eposide-(116): [100/1000]	Time 0.481 (0.453)	Data 0.001 (0.014)	Loss 123.830 (83.407)	Prec@1 20.000 (19.947)
Eposide-(216): [200/1000]	Time 0.432 (0.444)	Data 0.001 (0.008)	Loss 136.619 (89.808)	Prec@1 17.333 (20.066)
Eposide-(316): [300/1000]	Time 0.394 (0.443)	Data 0.001 (0.006)	Loss 78.017 (89.380)	Prec@1 21.333 (19.916)
Eposide-(416): [400/1000]	Time 0.457 (0.441)	Data 0.002 (0.005)	Loss 50.404 (87.574)	Prec@1 24.000 (20.057)
Eposide-(516): [500/1000]	Time 0.469 (0.439)	Data 0.002 (0.004)	Loss 37.242 (87.569)	Prec@1 13.333 (20.045)
Eposide-(616): [600/1000]	Time 0.429 (0.437)	Data 0.001 (0.003)	Loss 106.935 (87.837)	Prec@1 28.000 (20.062)
Eposide-(716): [700/1000]	Time 0.402 (0.438)	Data 0.001 (0.003)	Loss 107.100 (88.401)	Prec@1 20.000 (20.067)
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Eposide-(116): [100/1000]	Time 0.430 (0.460)	Data 0.001 (0.010)	Loss 120.636 (144.728)	Prec@1 20.000 (19.960)
Eposide-(216): [200/1000]	Time 0.436 (0.459)	Data 0.001 (0.006)	Loss 216.516 (140.346)	Prec@1 20.000 (20.040)
Eposide-(316): [300/1000]	Time 0.435 (0.456)	Data 0.003 (0.004)	Loss 94.089 (129.095)	Prec@1 20.000 (19.982)
Eposide-(416): [400/1000]	Time 0.426 (0.453)	Data 0.001 (0.003)	Loss 92.027 (121.134)	Prec@1 22.667 (20.003)
Eposide-(516): [500/1000]	Time 0.514 (0.452)	Data 0.001 (0.003)	Loss 45.973 (112.935)	Prec@1 22.667 (19.989)
Eposide-(616): [600/1000]	Time 0.467 (0.449)	Data 0.001 (0.003)	Loss 138.110 (107.094)	Prec@1 20.000 (20.033)
Eposide-(716): [700/1000]	Time 0.473 (0.448)	Data 0.001 (0.003)	Loss 117.015 (102.410)	Prec@1 20.000 (20.029)
Eposide-(816): [800/1000]	Time 0.413 (0.448)	Data 0.002 (0.002)	Loss 47.990 (98.654)	Prec@1 25.333 (20.063)
Eposide-(916): [900/1000]	Time 0.428 (0.448)	Data 0.001 (0.002)	Loss 86.775 (95.062)	Prec@1 20.000 (20.068)
============ validation on the val set ============
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Eposide-(16): [100/1000]	Time 0.419 (0.457)	Data 0.001 (0.012)	Loss 55.186 (144.810)	Prec@1 21.333 (19.274)
Eposide-(16): [200/1000]	Time 0.410 (0.447)	Data 0.001 (0.006)	Loss 53.048 (132.263)	Prec@1 21.333 (19.907)
Eposide-(16): [300/1000]	Time 0.411 (0.443)	Data 0.001 (0.005)	Loss 74.285 (124.363)	Prec@1 18.667 (19.929)
Eposide-(16): [400/1000]	Time 0.411 (0.442)	Data 0.001 (0.004)	Loss 75.831 (116.076)	Prec@1 20.000 (19.917)
Eposide-(16): [500/1000]	Time 0.424 (0.442)	Data 0.001 (0.003)	Loss 165.203 (111.013)	Prec@1 20.000 (19.928)
Eposide-(16): [600/1000]	Time 0.417 (0.442)	Data 0.001 (0.003)	Loss 84.313 (106.530)	Prec@1 20.000 (19.978)
Eposide-(16): [700/1000]	Time 0.409 (0.442)	Data 0.002 (0.003)	Loss 96.621 (102.730)	Prec@1 20.000 (19.981)
Eposide-(16): [800/1000]	Time 0.481 (0.442)	Data 0.002 (0.003)	Loss 88.341 (99.315)	Prec@1 18.667 (19.960)
Eposide-(16): [900/1000]	Time 0.420 (0.441)	Data 0.001 (0.002)	Loss 37.998 (96.175)	Prec@1 21.333 (19.979)
============ validation on the val set ============
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
    (criterion): CrossEntropyLoss()
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
    (criterion): CrossEntropyLoss()
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
    (criterion): CrossEntropyLoss()
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Eposide-(16): [100/1000]	Time 0.234 (0.245)	Data 0.002 (0.009)	Loss 1.705 (1.705)	Prec@1 20.000 (19.934)
Eposide-(16): [200/1000]	Time 0.234 (0.237)	Data 0.000 (0.005)	Loss 1.705 (1.705)	Prec@1 20.000 (19.967)
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Linear(in_features=512, out_features=128, bias=False)
      (4): LeakyReLU(negative_slope=0.2, inplace=True)
      (5): Linear(in_features=128, out_features=5, bias=False)
      (6): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
    (criterion): CrossEntropyLoss()
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Linear(in_features=512, out_features=128, bias=False)
      (4): LeakyReLU(negative_slope=0.2, inplace=True)
      (5): Linear(in_features=128, out_features=5, bias=False)
      (6): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
    (criterion): CrossEntropyLoss()
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Eposide-(0): [100/1000]	Time 0.227 (0.239)	Data 0.001 (0.010)	Loss 1.665 (1.705)	Prec@1 24.000 (19.987)
Eposide-(0): [200/1000]	Time 0.227 (0.232)	Data 0.001 (0.005)	Loss 1.705 (1.706)	Prec@1 20.000 (19.900)
Eposide-(0): [300/1000]	Time 0.222 (0.230)	Data 0.001 (0.004)	Loss 1.678 (1.706)	Prec@1 22.667 (19.920)
Eposide-(0): [400/1000]	Time 0.214 (0.228)	Data 0.001 (0.003)	Loss 1.691 (1.705)	Prec@1 21.333 (19.953)
Eposide-(0): [500/1000]	Time 0.230 (0.227)	Data 0.000 (0.002)	Loss 1.678 (1.706)	Prec@1 22.667 (19.912)
Eposide-(0): [600/1000]	Time 0.225 (0.227)	Data 0.000 (0.002)	Loss 1.705 (1.706)	Prec@1 20.000 (19.840)
Eposide-(0): [700/1000]	Time 0.226 (0.227)	Data 0.001 (0.002)	Loss 1.785 (1.706)	Prec@1 12.000 (19.827)
Eposide-(0): [800/1000]	Time 0.222 (0.226)	Data 0.000 (0.002)	Loss 1.718 (1.707)	Prec@1 18.667 (19.802)
Eposide-(0): [900/1000]	Time 0.229 (0.226)	Data 0.000 (0.002)	Loss 1.758 (1.706)	Prec@1 14.667 (19.879)
============ validation on the val set ============
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Eposide-(0): [100/1000]	Time 0.422 (0.450)	Data 0.001 (0.011)	Loss 1.705 (1.705)	Prec@1 20.000 (20.779)
Eposide-(0): [200/1000]	Time 0.405 (0.447)	Data 0.002 (0.006)	Loss 1.705 (1.705)	Prec@1 20.000 (20.570)
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Eposide-(0): [100/1000]	Time 0.431 (0.460)	Data 0.002 (0.015)	Loss 1.651 (1.703)	Prec@1 25.333 (22.587)
Eposide-(0): [200/1000]	Time 0.430 (0.449)	Data 0.002 (0.008)	Loss 1.718 (1.706)	Prec@1 21.333 (22.554)
Eposide-(0): [300/1000]	Time 0.454 (0.445)	Data 0.000 (0.006)	Loss 1.691 (1.707)	Prec@1 21.333 (22.250)
Eposide-(0): [400/1000]	Time 0.431 (0.442)	Data 0.002 (0.005)	Loss 1.705 (1.707)	Prec@1 20.000 (22.131)
Eposide-(0): [500/1000]	Time 0.433 (0.442)	Data 0.002 (0.004)	Loss 1.691 (1.706)	Prec@1 21.333 (22.188)
Eposide-(0): [600/1000]	Time 0.425 (0.441)	Data 0.002 (0.004)	Loss 1.691 (1.707)	Prec@1 21.333 (22.156)
Eposide-(0): [700/1000]	Time 0.406 (0.440)	Data 0.002 (0.004)	Loss 1.705 (1.706)	Prec@1 20.000 (22.212)
Eposide-(0): [800/1000]	Time 0.407 (0.439)	Data 0.001 (0.003)	Loss 1.718 (1.705)	Prec@1 20.000 (22.176)
Eposide-(0): [900/1000]	Time 0.423 (0.438)	Data 0.001 (0.003)	Loss 1.785 (1.705)	Prec@1 20.000 (22.159)
============ validation on the val set ============
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): Softmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Eposide-(0): [100/1000]	Time 0.437 (0.486)	Data 0.002 (0.015)	Loss 1.691 (1.702)	Prec@1 21.333 (21.373)
Eposide-(0): [200/1000]	Time 0.447 (0.480)	Data 0.002 (0.009)	Loss 1.665 (1.704)	Prec@1 24.000 (21.539)
Eposide-(0): [300/1000]	Time 0.423 (0.474)	Data 0.002 (0.006)	Loss 1.691 (1.703)	Prec@1 21.333 (21.493)
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Eposide-(0): [100/1000]	Time 0.456 (0.455)	Data 0.002 (0.015)	Loss 62.043 (149.977)	Prec@1 20.000 (20.884)
Eposide-(0): [200/1000]	Time 0.448 (0.447)	Data 0.002 (0.008)	Loss 75.031 (106.565)	Prec@1 20.000 (20.796)
Eposide-(0): [300/1000]	Time 0.428 (0.443)	Data 0.002 (0.006)	Loss 52.891 (86.248)	Prec@1 20.000 (20.811)
Eposide-(0): [400/1000]	Time 0.426 (0.443)	Data 0.003 (0.005)	Loss 19.124 (72.389)	Prec@1 20.000 (20.735)
Eposide-(0): [500/1000]	Time 0.439 (0.444)	Data 0.002 (0.004)	Loss 6.672 (62.409)	Prec@1 21.333 (20.748)
Eposide-(0): [600/1000]	Time 0.429 (0.444)	Data 0.002 (0.004)	Loss 18.858 (54.703)	Prec@1 20.000 (20.710)
Eposide-(0): [700/1000]	Time 0.421 (0.445)	Data 0.002 (0.004)	Loss 8.670 (48.797)	Prec@1 20.000 (20.708)
Eposide-(0): [800/1000]	Time 0.443 (0.445)	Data 0.003 (0.003)	Loss 6.840 (44.088)	Prec@1 20.000 (20.729)
Eposide-(0): [900/1000]	Time 0.421 (0.446)	Data 0.003 (0.003)	Loss 8.979 (40.182)	Prec@1 22.667 (20.775)
============ validation on the val set ============
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1000
Valset: 1000
Testset: 1000
Eposide-(0): [100/1000]	Time 0.479 (0.485)	Data 0.000 (0.011)	Loss 119.167 (156.082)	Prec@1 20.000 (21.003)
Eposide-(0): [200/1000]	Time 0.446 (0.466)	Data 0.000 (0.006)	Loss 19.780 (108.003)	Prec@1 20.000 (20.942)
Eposide-(0): [300/1000]	Time 0.429 (0.459)	Data 0.000 (0.004)	Loss 15.653 (81.805)	Prec@1 20.000 (20.744)
Eposide-(0): [400/1000]	Time 0.528 (0.453)	Data 0.000 (0.003)	Loss 29.401 (66.861)	Prec@1 20.000 (20.911)
Eposide-(0): [500/1000]	Time 0.457 (0.450)	Data 0.000 (0.002)	Loss 21.560 (57.738)	Prec@1 21.333 (20.817)
Eposide-(0): [600/1000]	Time 0.433 (0.448)	Data 0.000 (0.002)	Loss 6.173 (50.940)	Prec@1 20.000 (20.790)
Eposide-(0): [700/1000]	Time 0.417 (0.446)	Data 0.000 (0.002)	Loss 14.668 (45.299)	Prec@1 20.000 (20.787)
Eposide-(0): [800/1000]	Time 0.429 (0.444)	Data 0.000 (0.002)	Loss 6.491 (40.679)	Prec@1 20.000 (20.822)
Eposide-(0): [900/1000]	Time 0.432 (0.444)	Data 0.000 (0.001)	Loss 5.985 (36.812)	Prec@1 20.000 (20.820)
============ validation on the val set ============
Test-(0): [100/1000]	Time 0.270 (0.287)	Loss 83625912.000 (86530135.842)	Prec@1 21.333 (23.036)
Test-(0): [200/1000]	Time 0.288 (0.280)	Loss 85085672.000 (86437858.985)	Prec@1 22.667 (22.826)
Test-(0): [300/1000]	Time 0.269 (0.280)	Loss 82738056.000 (86339433.834)	Prec@1 20.000 (22.888)
Test-(0): [400/1000]	Time 0.270 (0.279)	Loss 83868656.000 (86484942.125)	Prec@1 20.000 (22.820)
Test-(0): [500/1000]	Time 0.263 (0.279)	Loss 78394264.000 (86395974.419)	Prec@1 20.000 (22.842)
Test-(0): [600/1000]	Time 0.272 (0.279)	Loss 85677400.000 (86360178.715)	Prec@1 20.000 (22.789)
Test-(0): [700/1000]	Time 0.268 (0.278)	Loss 86932488.000 (86382787.310)	Prec@1 28.000 (22.796)
Test-(0): [800/1000]	Time 0.273 (0.278)	Loss 80561304.000 (86298108.624)	Prec@1 20.000 (22.777)
Test-(0): [900/1000]	Time 0.272 (0.277)	Loss 86166040.000 (86277214.979)	Prec@1 20.000 (22.729)
 * Prec@1 22.781 Best_prec1 0.000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 2
Valset: 2
Testset: 1000
============ validation on the val set ============
 * Prec@1 20.000 Best_prec1 0.000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 2
Valset: 2
Testset: 1000
============ validation on the val set ============
 * Prec@1 20.000 Best_prec1 0.000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 2
Valset: 2
Testset: 1000
============ validation on the val set ============
 * Prec@1 20.000 Best_prec1 0.000
============ Testing on the test set ============
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/epoch_0_best.pth.tar', epochs=5, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 5
Valset: 5
Testset: 300
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 5
Valset: 5
Testset: 300
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 5
Valset: 5
Testset: 300
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 5
Valset: 5
Testset: 300
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1
Valset: 1
Testset: 300
============ validation on the val set ============
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1
Valset: 1
Testset: 300
============ validation on the val set ============
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 2
Valset: 2
Testset: 300
============ validation on the val set ============
 * Prec@1 20.000 Best_prec1 0.000
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 2
Valset: 2
Testset: 300
============ validation on the val set ============
 * Prec@1 20.000 Best_prec1 0.000
============ Testing on the test set ============
Test-(0): [100/300]	Time 0.256 (0.283)	Loss 172.936 (145.310)	Prec@1 20.000 (20.449)
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/epoch_0_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/model_best.pth.tar' (epoch 16)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 2
Valset: 2
Testset: 2
============ validation on the val set ============
 * Prec@1 20.000 Best_prec1 0.000
============ Testing on the test set ============
 * Prec@1 20.000 Best_prec1 20.000
===================================== Epoch 1 =====================================
Trainset: 2
Valset: 2
Testset: 2
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/epoch_0_best.pth.tar', epochs=3, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/epoch_0_best.pth.tar' (epoch 2)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 2
Valset: 2
Testset: 2
============ validation on the val set ============
 * Prec@1 20.000 Best_prec1 0.000
============ Testing on the test set ============
 * Prec@1 20.000 Best_prec1 20.000
===================================== Epoch 1 =====================================
Trainset: 2
Valset: 2
Testset: 2
============ validation on the val set ============
 * Prec@1 20.000 Best_prec1 20.000
============ Testing on the test set ============
 * Prec@1 20.000 Best_prec1 20.000
===================================== Epoch 2 =====================================
Trainset: 2
Valset: 2
Testset: 2
============ validation on the val set ============
 * Prec@1 21.333 Best_prec1 20.000
============ Testing on the test set ============
 * Prec@1 20.000 Best_prec1 21.333
============ validation on the val set ============
Trainset: 2
Valset: 2
Testset: 2
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/epoch_0_best.pth.tar', epochs=10, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
=> loaded checkpoint '../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3/epoch_0_best.pth.tar' (epoch 2)
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(0): [100/5000]	Time 0.441 (0.473)	Data 0.000 (0.008)	Loss 81.983 (135.194)	Prec@1 20.000 (20.911)
Eposide-(0): [200/5000]	Time 0.431 (0.459)	Data 0.000 (0.004)	Loss 73.709 (99.658)	Prec@1 24.000 (20.935)
Eposide-(0): [300/5000]	Time 0.418 (0.451)	Data 0.000 (0.003)	Loss 36.338 (79.412)	Prec@1 20.000 (20.811)
Eposide-(0): [400/5000]	Time 0.432 (0.448)	Data 0.000 (0.002)	Loss 29.605 (66.618)	Prec@1 20.000 (20.838)
Eposide-(0): [500/5000]	Time 0.446 (0.447)	Data 0.001 (0.002)	Loss 5.407 (56.979)	Prec@1 20.000 (20.884)
Eposide-(0): [600/5000]	Time 0.437 (0.445)	Data 0.000 (0.002)	Loss 17.188 (49.604)	Prec@1 26.667 (20.936)
Eposide-(0): [700/5000]	Time 0.436 (0.444)	Data 0.000 (0.001)	Loss 7.923 (45.284)	Prec@1 20.000 (20.909)
Eposide-(0): [800/5000]	Time 0.434 (0.444)	Data 0.000 (0.001)	Loss 13.143 (41.126)	Prec@1 20.000 (20.884)
Eposide-(0): [900/5000]	Time 0.420 (0.442)	Data 0.000 (0.001)	Loss 5.900 (37.383)	Prec@1 20.000 (20.904)
Eposide-(0): [1000/5000]	Time 0.433 (0.442)	Data 0.000 (0.001)	Loss 8.316 (34.254)	Prec@1 20.000 (20.900)
Eposide-(0): [1100/5000]	Time 0.469 (0.442)	Data 0.000 (0.001)	Loss 4.623 (31.579)	Prec@1 20.000 (20.908)
Eposide-(0): [1200/5000]	Time 0.439 (0.444)	Data 0.000 (0.001)	Loss 2.670 (29.293)	Prec@1 22.667 (20.924)
Eposide-(0): [1300/5000]	Time 0.434 (0.444)	Data 0.000 (0.001)	Loss 1.859 (27.333)	Prec@1 20.000 (20.935)
Eposide-(0): [1400/5000]	Time 0.435 (0.444)	Data 0.000 (0.001)	Loss 4.763 (25.639)	Prec@1 20.000 (20.921)
Eposide-(0): [1500/5000]	Time 0.436 (0.443)	Data 0.000 (0.001)	Loss 4.075 (24.132)	Prec@1 20.000 (20.924)
Eposide-(0): [1600/5000]	Time 0.432 (0.443)	Data 0.000 (0.001)	Loss 2.052 (22.794)	Prec@1 21.333 (20.934)
Eposide-(0): [1700/5000]	Time 0.430 (0.443)	Data 0.000 (0.001)	Loss 2.236 (21.598)	Prec@1 20.000 (20.916)
Eposide-(0): [1800/5000]	Time 0.433 (0.443)	Data 0.000 (0.001)	Loss 2.558 (20.540)	Prec@1 20.000 (20.907)
Eposide-(0): [1900/5000]	Time 0.443 (0.443)	Data 0.000 (0.001)	Loss 1.727 (19.591)	Prec@1 20.000 (20.906)
Eposide-(0): [2000/5000]	Time 0.449 (0.443)	Data 0.001 (0.001)	Loss 1.916 (18.729)	Prec@1 20.000 (20.923)
Eposide-(0): [2100/5000]	Time 0.440 (0.443)	Data 0.000 (0.001)	Loss 2.416 (17.945)	Prec@1 21.333 (20.926)
Eposide-(0): [2200/5000]	Time 0.446 (0.443)	Data 0.000 (0.001)	Loss 1.933 (17.230)	Prec@1 22.667 (20.917)
Eposide-(0): [2300/5000]	Time 0.428 (0.442)	Data 0.000 (0.001)	Loss 1.971 (16.569)	Prec@1 20.000 (20.909)
Eposide-(0): [2400/5000]	Time 0.455 (0.442)	Data 0.001 (0.001)	Loss 1.687 (15.962)	Prec@1 20.000 (20.906)
Eposide-(0): [2500/5000]	Time 0.441 (0.442)	Data 0.000 (0.001)	Loss 2.033 (15.403)	Prec@1 20.000 (20.921)
Eposide-(0): [2600/5000]	Time 0.429 (0.442)	Data 0.000 (0.001)	Loss 2.226 (14.890)	Prec@1 21.333 (20.905)
Eposide-(0): [2700/5000]	Time 0.537 (0.442)	Data 0.000 (0.001)	Loss 1.673 (14.411)	Prec@1 20.000 (20.901)
Eposide-(0): [2800/5000]	Time 0.446 (0.444)	Data 0.000 (0.001)	Loss 2.401 (13.964)	Prec@1 20.000 (20.911)
Eposide-(0): [2900/5000]	Time 0.466 (0.444)	Data 0.000 (0.001)	Loss 3.420 (13.548)	Prec@1 22.667 (20.923)
Eposide-(0): [3000/5000]	Time 0.441 (0.444)	Data 0.000 (0.001)	Loss 1.702 (13.159)	Prec@1 20.000 (20.917)
Eposide-(0): [3100/5000]	Time 0.427 (0.445)	Data 0.001 (0.001)	Loss 1.664 (12.794)	Prec@1 20.000 (20.916)
Eposide-(0): [3200/5000]	Time 0.440 (0.445)	Data 0.000 (0.001)	Loss 1.772 (12.450)	Prec@1 20.000 (20.928)
Eposide-(0): [3300/5000]	Time 0.437 (0.445)	Data 0.000 (0.001)	Loss 1.688 (12.128)	Prec@1 21.333 (20.921)
Eposide-(0): [3400/5000]	Time 0.419 (0.445)	Data 0.000 (0.001)	Loss 1.619 (11.823)	Prec@1 21.333 (20.926)
Eposide-(0): [3500/5000]	Time 0.440 (0.445)	Data 0.000 (0.001)	Loss 1.682 (11.535)	Prec@1 20.000 (20.931)
Eposide-(0): [3600/5000]	Time 0.463 (0.445)	Data 0.000 (0.001)	Loss 1.839 (11.264)	Prec@1 20.000 (20.942)
Eposide-(0): [3700/5000]	Time 0.545 (0.445)	Data 0.000 (0.001)	Loss 1.748 (11.007)	Prec@1 20.000 (20.944)
Eposide-(0): [3800/5000]	Time 0.462 (0.445)	Data 0.000 (0.001)	Loss 1.690 (10.763)	Prec@1 21.333 (20.944)
Eposide-(0): [3900/5000]	Time 0.451 (0.445)	Data 0.000 (0.001)	Loss 1.663 (10.531)	Prec@1 25.333 (20.944)
Eposide-(0): [4000/5000]	Time 0.450 (0.445)	Data 0.000 (0.001)	Loss 1.740 (10.310)	Prec@1 20.000 (20.944)
Eposide-(0): [4100/5000]	Time 0.444 (0.445)	Data 0.000 (0.001)	Loss 1.636 (10.100)	Prec@1 20.000 (20.944)
Eposide-(0): [4200/5000]	Time 0.445 (0.445)	Data 0.000 (0.001)	Loss 1.619 (9.899)	Prec@1 20.000 (20.941)
Eposide-(0): [4300/5000]	Time 0.441 (0.445)	Data 0.000 (0.001)	Loss 1.653 (9.708)	Prec@1 20.000 (20.939)
Eposide-(0): [4400/5000]	Time 0.430 (0.445)	Data 0.000 (0.001)	Loss 1.755 (9.526)	Prec@1 20.000 (20.945)
Eposide-(0): [4500/5000]	Time 0.428 (0.445)	Data 0.000 (0.001)	Loss 1.627 (9.351)	Prec@1 20.000 (20.948)
Eposide-(0): [4600/5000]	Time 0.426 (0.445)	Data 0.000 (0.001)	Loss 1.655 (9.184)	Prec@1 20.000 (20.951)
Eposide-(0): [4700/5000]	Time 0.445 (0.446)	Data 0.000 (0.001)	Loss 1.624 (9.024)	Prec@1 21.333 (20.948)
Eposide-(0): [4800/5000]	Time 0.443 (0.446)	Data 0.000 (0.001)	Loss 1.623 (8.870)	Prec@1 20.000 (20.950)
Eposide-(0): [4900/5000]	Time 0.449 (0.445)	Data 0.000 (0.000)	Loss 1.702 (8.723)	Prec@1 20.000 (20.946)
============ validation on the val set ============
Test-(0): [100/500]	Time 0.267 (0.282)	Loss 1.635 (1.646)	Prec@1 20.000 (20.000)
Test-(0): [200/500]	Time 0.272 (0.276)	Loss 1.621 (1.647)	Prec@1 20.000 (20.000)
Test-(0): [300/500]	Time 0.271 (0.274)	Loss 1.646 (1.648)	Prec@1 20.000 (20.000)
Test-(0): [400/500]	Time 0.251 (0.273)	Loss 1.626 (1.648)	Prec@1 20.000 (20.003)
 * Prec@1 20.003 Best_prec1 0.000
============ Testing on the test set ============
Test-(0): [100/500]	Time 0.258 (0.284)	Loss 1.636 (1.641)	Prec@1 20.000 (20.000)
Test-(0): [200/500]	Time 0.259 (0.277)	Loss 1.651 (1.645)	Prec@1 20.000 (20.000)
Test-(0): [300/500]	Time 0.295 (0.276)	Loss 1.614 (1.645)	Prec@1 20.000 (20.000)
Test-(0): [400/500]	Time 0.263 (0.274)	Loss 1.620 (1.646)	Prec@1 20.000 (20.000)
 * Prec@1 20.016 Best_prec1 20.003
===================================== Epoch 1 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(5000): [100/5000]	Time 0.496 (0.454)	Data 0.000 (0.006)	Loss 1.611 (1.637)	Prec@1 20.000 (21.069)
Eposide-(5000): [200/5000]	Time 0.443 (0.451)	Data 0.000 (0.003)	Loss 1.641 (1.639)	Prec@1 22.667 (21.075)
Eposide-(5000): [300/5000]	Time 0.437 (0.449)	Data 0.000 (0.002)	Loss 1.631 (1.636)	Prec@1 20.000 (21.045)
Eposide-(5000): [400/5000]	Time 0.456 (0.448)	Data 0.001 (0.002)	Loss 1.610 (1.634)	Prec@1 25.333 (21.104)
Eposide-(5000): [500/5000]	Time 0.427 (0.448)	Data 0.000 (0.001)	Loss 1.620 (1.632)	Prec@1 20.000 (21.078)
Eposide-(5000): [600/5000]	Time 0.445 (0.448)	Data 0.000 (0.001)	Loss 1.619 (1.630)	Prec@1 22.667 (21.032)
Eposide-(5000): [700/5000]	Time 0.461 (0.447)	Data 0.000 (0.001)	Loss 1.610 (1.629)	Prec@1 20.000 (20.993)
Eposide-(5000): [800/5000]	Time 0.429 (0.447)	Data 0.000 (0.001)	Loss 1.617 (1.627)	Prec@1 20.000 (20.960)
Eposide-(5000): [900/5000]	Time 0.455 (0.446)	Data 0.000 (0.001)	Loss 1.617 (1.626)	Prec@1 21.333 (20.959)
Eposide-(5000): [1000/5000]	Time 0.436 (0.447)	Data 0.000 (0.001)	Loss 1.611 (1.625)	Prec@1 22.667 (20.963)
Eposide-(5000): [1100/5000]	Time 0.442 (0.447)	Data 0.000 (0.001)	Loss 1.610 (1.624)	Prec@1 20.000 (20.964)
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='', epochs=10, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='', epochs=10, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
DN7_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(0): [100/5000]	Time 0.335 (0.352)	Data 0.000 (0.011)	Loss 1.598 (2.343)	Prec@1 29.333 (29.729)
Eposide-(0): [200/5000]	Time 0.329 (0.346)	Data 0.001 (0.006)	Loss 1.497 (1.975)	Prec@1 32.000 (29.831)
Eposide-(0): [300/5000]	Time 0.355 (0.353)	Data 0.000 (0.004)	Loss 1.398 (1.844)	Prec@1 42.667 (30.100)
Eposide-(0): [400/5000]	Time 0.343 (0.352)	Data 0.001 (0.003)	Loss 1.679 (1.765)	Prec@1 28.000 (31.026)
Eposide-(0): [500/5000]	Time 0.337 (0.351)	Data 0.001 (0.003)	Loss 1.404 (1.718)	Prec@1 44.000 (31.705)
Eposide-(0): [600/5000]	Time 0.332 (0.350)	Data 0.001 (0.003)	Loss 1.577 (1.684)	Prec@1 28.000 (32.288)
Eposide-(0): [700/5000]	Time 0.348 (0.349)	Data 0.000 (0.002)	Loss 1.618 (1.656)	Prec@1 28.000 (32.850)
Eposide-(0): [800/5000]	Time 0.332 (0.349)	Data 0.001 (0.002)	Loss 1.455 (1.632)	Prec@1 38.667 (33.635)
Eposide-(0): [900/5000]	Time 0.357 (0.348)	Data 0.001 (0.002)	Loss 1.409 (1.612)	Prec@1 49.333 (34.306)
Eposide-(0): [1000/5000]	Time 0.317 (0.347)	Data 0.001 (0.002)	Loss 1.384 (1.597)	Prec@1 37.333 (34.740)
Eposide-(0): [1100/5000]	Time 0.329 (0.347)	Data 0.001 (0.002)	Loss 1.484 (1.582)	Prec@1 36.000 (35.355)
Eposide-(0): [1200/5000]	Time 0.337 (0.348)	Data 0.001 (0.002)	Loss 1.501 (1.568)	Prec@1 42.667 (35.811)
Eposide-(0): [1300/5000]	Time 0.349 (0.348)	Data 0.001 (0.002)	Loss 1.508 (1.560)	Prec@1 33.333 (35.976)
Eposide-(0): [1400/5000]	Time 0.340 (0.349)	Data 0.001 (0.002)	Loss 1.389 (1.551)	Prec@1 40.000 (36.248)
Eposide-(0): [1500/5000]	Time 0.327 (0.349)	Data 0.001 (0.002)	Loss 1.268 (1.543)	Prec@1 53.333 (36.589)
Eposide-(0): [1600/5000]	Time 0.321 (0.348)	Data 0.001 (0.002)	Loss 1.412 (1.535)	Prec@1 54.667 (36.924)
Eposide-(0): [1700/5000]	Time 0.342 (0.347)	Data 0.001 (0.002)	Loss 1.301 (1.526)	Prec@1 50.667 (37.367)
Eposide-(0): [1800/5000]	Time 0.369 (0.347)	Data 0.001 (0.002)	Loss 1.410 (1.518)	Prec@1 49.333 (37.675)
Eposide-(0): [1900/5000]	Time 0.349 (0.347)	Data 0.001 (0.002)	Loss 1.233 (1.512)	Prec@1 49.333 (37.941)
Eposide-(0): [2000/5000]	Time 0.343 (0.347)	Data 0.001 (0.002)	Loss 1.320 (1.505)	Prec@1 38.667 (38.234)
Eposide-(0): [2100/5000]	Time 0.348 (0.347)	Data 0.001 (0.002)	Loss 1.350 (1.499)	Prec@1 38.667 (38.518)
Eposide-(0): [2200/5000]	Time 0.336 (0.347)	Data 0.001 (0.002)	Loss 1.656 (1.493)	Prec@1 28.000 (38.828)
Eposide-(0): [2300/5000]	Time 0.356 (0.347)	Data 0.001 (0.002)	Loss 1.102 (1.488)	Prec@1 62.667 (39.053)
Eposide-(0): [2400/5000]	Time 0.374 (0.347)	Data 0.002 (0.001)	Loss 1.013 (1.480)	Prec@1 61.333 (39.386)
Eposide-(0): [2500/5000]	Time 0.331 (0.348)	Data 0.001 (0.001)	Loss 1.537 (1.475)	Prec@1 30.667 (39.607)
Eposide-(0): [2600/5000]	Time 0.328 (0.347)	Data 0.001 (0.001)	Loss 1.369 (1.470)	Prec@1 41.333 (39.845)
Eposide-(0): [2700/5000]	Time 0.337 (0.347)	Data 0.001 (0.001)	Loss 1.482 (1.465)	Prec@1 33.333 (40.048)
Eposide-(0): [2800/5000]	Time 0.337 (0.347)	Data 0.001 (0.001)	Loss 1.499 (1.460)	Prec@1 36.000 (40.282)
Eposide-(0): [2900/5000]	Time 0.331 (0.347)	Data 0.001 (0.001)	Loss 1.404 (1.454)	Prec@1 50.667 (40.541)
Eposide-(0): [3000/5000]	Time 0.334 (0.347)	Data 0.001 (0.001)	Loss 1.183 (1.450)	Prec@1 57.333 (40.758)
Eposide-(0): [3100/5000]	Time 0.353 (0.347)	Data 0.001 (0.001)	Loss 0.992 (1.444)	Prec@1 60.000 (41.048)
Eposide-(0): [3200/5000]	Time 0.347 (0.347)	Data 0.001 (0.001)	Loss 1.996 (1.440)	Prec@1 24.000 (41.233)
Eposide-(0): [3300/5000]	Time 0.345 (0.346)	Data 0.001 (0.001)	Loss 1.528 (1.435)	Prec@1 46.667 (41.431)
Eposide-(0): [3400/5000]	Time 0.341 (0.346)	Data 0.001 (0.001)	Loss 1.312 (1.432)	Prec@1 50.667 (41.579)
Eposide-(0): [3500/5000]	Time 0.341 (0.346)	Data 0.000 (0.001)	Loss 1.256 (1.427)	Prec@1 41.333 (41.763)
Eposide-(0): [3600/5000]	Time 0.335 (0.346)	Data 0.001 (0.001)	Loss 0.985 (1.424)	Prec@1 62.667 (41.927)
Eposide-(0): [3700/5000]	Time 0.334 (0.346)	Data 0.001 (0.001)	Loss 1.204 (1.420)	Prec@1 50.667 (42.103)
Eposide-(0): [3800/5000]	Time 0.337 (0.346)	Data 0.001 (0.001)	Loss 1.437 (1.416)	Prec@1 37.333 (42.304)
Eposide-(0): [3900/5000]	Time 0.334 (0.346)	Data 0.001 (0.001)	Loss 1.082 (1.411)	Prec@1 60.000 (42.568)
Eposide-(0): [4000/5000]	Time 0.329 (0.346)	Data 0.001 (0.001)	Loss 1.571 (1.407)	Prec@1 38.667 (42.737)
Eposide-(0): [4100/5000]	Time 0.330 (0.346)	Data 0.001 (0.001)	Loss 1.195 (1.403)	Prec@1 52.000 (42.927)
Eposide-(0): [4200/5000]	Time 0.325 (0.346)	Data 0.001 (0.001)	Loss 1.097 (1.399)	Prec@1 54.667 (43.119)
Eposide-(0): [4300/5000]	Time 0.326 (0.346)	Data 0.001 (0.001)	Loss 1.399 (1.395)	Prec@1 33.333 (43.329)
Eposide-(0): [4400/5000]	Time 0.337 (0.345)	Data 0.001 (0.001)	Loss 1.030 (1.392)	Prec@1 60.000 (43.473)
Eposide-(0): [4500/5000]	Time 0.329 (0.345)	Data 0.001 (0.001)	Loss 1.258 (1.388)	Prec@1 50.667 (43.659)
Eposide-(0): [4600/5000]	Time 0.330 (0.345)	Data 0.002 (0.001)	Loss 1.059 (1.384)	Prec@1 56.000 (43.863)
Eposide-(0): [4700/5000]	Time 0.364 (0.345)	Data 0.001 (0.001)	Loss 1.104 (1.380)	Prec@1 60.000 (44.018)
Eposide-(0): [4800/5000]	Time 0.326 (0.345)	Data 0.001 (0.001)	Loss 1.196 (1.376)	Prec@1 54.667 (44.219)
Eposide-(0): [4900/5000]	Time 0.336 (0.345)	Data 0.001 (0.001)	Loss 0.908 (1.373)	Prec@1 69.333 (44.407)
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
DN7_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 1
Valset: 5
Testset: 5
============ validation on the val set ============
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='', epochs=1, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Namespace(dataset_dir='../dataset/miniImageNet/', data_name='miniImageNet', mode='train', resume='', epochs=15, cuda=True, ngpu=1, nc=3, clamp_lower=-0.01, clamp_upper=0.01, print_freq=100, outf='../results/DN4_miniImageNet_DN4_DTR_5Way_5Shot_K3')
DN4_DTR(
  (BACKBONE_2D): FourLayer_64F(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): LeakyReLU(negative_slope=0.2, inplace=True)
      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (criterion): CrossEntropyLoss()
  )
  (ENCODER): Encoder(
    (encoder_smax): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=40000, out_features=512, bias=False)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=512, out_features=128, bias=False)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=128, out_features=5, bias=False)
      (8): LogSoftmax(dim=1)
    )
    (encoder_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (DT): XGBHead()
)
===================================== Epoch 0 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(0): [100/5000]	Time 0.474 (0.472)	Data 0.000 (0.016)	Loss 220.361 (250.320)	Prec@1 20.000 (21.954)
Eposide-(0): [200/5000]	Time 0.426 (0.452)	Data 0.000 (0.008)	Loss 98.246 (206.847)	Prec@1 22.667 (22.441)
Eposide-(0): [300/5000]	Time 0.424 (0.445)	Data 0.000 (0.006)	Loss 39.844 (166.885)	Prec@1 25.333 (22.388)
Eposide-(0): [400/5000]	Time 0.408 (0.442)	Data 0.000 (0.004)	Loss 47.441 (141.067)	Prec@1 20.000 (22.185)
Eposide-(0): [500/5000]	Time 0.426 (0.440)	Data 0.000 (0.003)	Loss 14.927 (119.345)	Prec@1 20.000 (21.937)
Eposide-(0): [600/5000]	Time 0.419 (0.438)	Data 0.000 (0.003)	Loss 34.008 (102.368)	Prec@1 20.000 (21.784)
Eposide-(0): [700/5000]	Time 0.423 (0.436)	Data 0.000 (0.003)	Loss 8.099 (89.075)	Prec@1 20.000 (21.668)
Eposide-(0): [800/5000]	Time 0.425 (0.435)	Data 0.000 (0.002)	Loss 13.354 (78.885)	Prec@1 20.000 (21.546)
Eposide-(0): [900/5000]	Time 0.429 (0.434)	Data 0.000 (0.002)	Loss 3.689 (70.622)	Prec@1 20.000 (21.462)
Eposide-(0): [1000/5000]	Time 0.432 (0.434)	Data 0.000 (0.002)	Loss 3.903 (63.937)	Prec@1 20.000 (21.405)
Eposide-(0): [1100/5000]	Time 0.414 (0.433)	Data 0.000 (0.002)	Loss 2.664 (58.433)	Prec@1 21.333 (21.370)
Eposide-(0): [1200/5000]	Time 0.421 (0.433)	Data 0.000 (0.002)	Loss 3.817 (53.809)	Prec@1 20.000 (21.343)
Eposide-(0): [1300/5000]	Time 0.433 (0.433)	Data 0.000 (0.001)	Loss 3.383 (49.882)	Prec@1 20.000 (21.300)
Eposide-(0): [1400/5000]	Time 0.427 (0.433)	Data 0.000 (0.001)	Loss 1.666 (46.494)	Prec@1 20.000 (21.259)
Eposide-(0): [1500/5000]	Time 0.417 (0.433)	Data 0.001 (0.001)	Loss 2.060 (43.543)	Prec@1 20.000 (21.225)
Eposide-(0): [1600/5000]	Time 0.473 (0.433)	Data 0.000 (0.001)	Loss 2.317 (40.974)	Prec@1 21.333 (21.192)
Eposide-(0): [1700/5000]	Time 0.422 (0.432)	Data 0.000 (0.001)	Loss 1.767 (38.696)	Prec@1 20.000 (21.187)
Eposide-(0): [1800/5000]	Time 0.412 (0.432)	Data 0.000 (0.001)	Loss 1.800 (36.669)	Prec@1 20.000 (21.161)
Eposide-(0): [1900/5000]	Time 0.423 (0.432)	Data 0.000 (0.001)	Loss 1.763 (34.843)	Prec@1 21.333 (21.128)
Eposide-(0): [2000/5000]	Time 0.429 (0.432)	Data 0.000 (0.001)	Loss 2.362 (33.201)	Prec@1 20.000 (21.103)
Eposide-(0): [2100/5000]	Time 0.428 (0.432)	Data 0.000 (0.001)	Loss 1.722 (31.711)	Prec@1 21.333 (21.106)
Eposide-(0): [2200/5000]	Time 0.445 (0.432)	Data 0.000 (0.001)	Loss 1.703 (30.357)	Prec@1 20.000 (21.083)
Eposide-(0): [2300/5000]	Time 0.457 (0.432)	Data 0.001 (0.001)	Loss 1.645 (29.117)	Prec@1 21.333 (21.084)
Eposide-(0): [2400/5000]	Time 0.426 (0.432)	Data 0.000 (0.001)	Loss 1.989 (27.979)	Prec@1 21.333 (21.070)
Eposide-(0): [2500/5000]	Time 0.445 (0.432)	Data 0.000 (0.001)	Loss 1.933 (26.932)	Prec@1 20.000 (21.055)
Eposide-(0): [2600/5000]	Time 0.450 (0.433)	Data 0.000 (0.001)	Loss 1.832 (25.963)	Prec@1 20.000 (21.050)
Eposide-(0): [2700/5000]	Time 0.445 (0.432)	Data 0.000 (0.001)	Loss 1.637 (25.081)	Prec@1 29.333 (21.049)
Eposide-(0): [2800/5000]	Time 0.411 (0.432)	Data 0.000 (0.001)	Loss 1.686 (24.246)	Prec@1 20.000 (21.041)
Eposide-(0): [2900/5000]	Time 0.462 (0.432)	Data 0.000 (0.001)	Loss 1.632 (23.470)	Prec@1 20.000 (21.032)
Eposide-(0): [3000/5000]	Time 0.424 (0.432)	Data 0.000 (0.001)	Loss 1.655 (22.746)	Prec@1 20.000 (21.035)
Eposide-(0): [3100/5000]	Time 0.437 (0.432)	Data 0.000 (0.001)	Loss 1.641 (22.067)	Prec@1 20.000 (21.026)
Eposide-(0): [3200/5000]	Time 0.447 (0.432)	Data 0.001 (0.001)	Loss 1.612 (21.430)	Prec@1 20.000 (21.026)
Eposide-(0): [3300/5000]	Time 0.438 (0.432)	Data 0.000 (0.001)	Loss 1.626 (20.832)	Prec@1 20.000 (21.019)
Eposide-(0): [3400/5000]	Time 0.443 (0.432)	Data 0.000 (0.001)	Loss 1.660 (20.268)	Prec@1 20.000 (21.009)
Eposide-(0): [3500/5000]	Time 0.449 (0.432)	Data 0.000 (0.001)	Loss 1.650 (19.736)	Prec@1 22.667 (21.001)
Eposide-(0): [3600/5000]	Time 0.426 (0.432)	Data 0.000 (0.001)	Loss 1.641 (19.234)	Prec@1 21.333 (20.999)
Eposide-(0): [3700/5000]	Time 0.415 (0.432)	Data 0.000 (0.001)	Loss 1.623 (18.759)	Prec@1 20.000 (21.003)
Eposide-(0): [3800/5000]	Time 0.432 (0.432)	Data 0.000 (0.001)	Loss 1.617 (18.308)	Prec@1 20.000 (20.999)
Eposide-(0): [3900/5000]	Time 0.431 (0.432)	Data 0.000 (0.001)	Loss 1.620 (17.881)	Prec@1 20.000 (21.003)
Eposide-(0): [4000/5000]	Time 0.567 (0.432)	Data 0.000 (0.001)	Loss 1.614 (17.474)	Prec@1 20.000 (21.008)
Eposide-(0): [4100/5000]	Time 0.438 (0.432)	Data 0.000 (0.001)	Loss 1.613 (17.110)	Prec@1 20.000 (21.007)
Eposide-(0): [4200/5000]	Time 0.427 (0.432)	Data 0.000 (0.001)	Loss 1.624 (16.741)	Prec@1 20.000 (21.003)
Eposide-(0): [4300/5000]	Time 0.581 (0.432)	Data 0.000 (0.001)	Loss 1.615 (16.390)	Prec@1 25.333 (21.008)
Eposide-(0): [4400/5000]	Time 0.437 (0.432)	Data 0.000 (0.001)	Loss 1.626 (16.063)	Prec@1 26.667 (20.998)
Eposide-(0): [4500/5000]	Time 0.425 (0.432)	Data 0.000 (0.001)	Loss 1.610 (15.742)	Prec@1 20.000 (20.997)
Eposide-(0): [4600/5000]	Time 0.415 (0.432)	Data 0.000 (0.001)	Loss 1.611 (15.435)	Prec@1 20.000 (20.994)
Eposide-(0): [4700/5000]	Time 0.426 (0.432)	Data 0.000 (0.001)	Loss 1.610 (15.141)	Prec@1 20.000 (20.997)
Eposide-(0): [4800/5000]	Time 0.421 (0.432)	Data 0.000 (0.001)	Loss 1.611 (14.859)	Prec@1 20.000 (21.005)
Eposide-(0): [4900/5000]	Time 0.450 (0.432)	Data 0.000 (0.001)	Loss 1.609 (14.589)	Prec@1 20.000 (20.994)
============ validation on the val set ============
Test-(0): [100/500]	Time 0.251 (0.275)	Loss 1.610 (1.610)	Prec@1 20.000 (20.238)
Test-(0): [200/500]	Time 0.260 (0.270)	Loss 1.610 (1.610)	Prec@1 20.000 (20.166)
Test-(0): [300/500]	Time 0.271 (0.270)	Loss 1.610 (1.610)	Prec@1 20.000 (20.168)
Test-(0): [400/500]	Time 0.276 (0.268)	Loss 1.609 (1.610)	Prec@1 20.000 (20.170)
 * Prec@1 20.205 Best_prec1 0.000
============ Testing on the test set ============
Test-(0): [100/500]	Time 0.280 (0.279)	Loss 1.610 (1.610)	Prec@1 20.000 (20.013)
Test-(0): [200/500]	Time 0.255 (0.272)	Loss 1.610 (1.610)	Prec@1 20.000 (20.093)
Test-(0): [300/500]	Time 0.257 (0.270)	Loss 1.610 (1.610)	Prec@1 20.000 (20.124)
Test-(0): [400/500]	Time 0.251 (0.269)	Loss 1.610 (1.610)	Prec@1 20.000 (20.150)
 * Prec@1 20.168 Best_prec1 20.205
===================================== Epoch 1 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(5000): [100/5000]	Time 0.432 (0.445)	Data 0.000 (0.008)	Loss 1.610 (1.649)	Prec@1 20.000 (21.109)
Eposide-(5000): [200/5000]	Time 0.444 (0.439)	Data 0.000 (0.004)	Loss 1.609 (1.629)	Prec@1 24.000 (21.294)
Eposide-(5000): [300/5000]	Time 0.409 (0.438)	Data 0.000 (0.003)	Loss 1.609 (1.664)	Prec@1 20.000 (21.187)
Eposide-(5000): [400/5000]	Time 0.438 (0.436)	Data 0.000 (0.002)	Loss 1.609 (1.651)	Prec@1 21.333 (21.177)
Eposide-(5000): [500/5000]	Time 0.456 (0.436)	Data 0.000 (0.002)	Loss 1.610 (1.642)	Prec@1 20.000 (21.182)
Eposide-(5000): [600/5000]	Time 0.456 (0.436)	Data 0.000 (0.002)	Loss 1.609 (1.671)	Prec@1 20.000 (21.187)
Eposide-(5000): [700/5000]	Time 0.445 (0.436)	Data 0.000 (0.001)	Loss 1.609 (1.662)	Prec@1 20.000 (21.153)
Eposide-(5000): [800/5000]	Time 0.423 (0.435)	Data 0.000 (0.001)	Loss 1.611 (1.658)	Prec@1 20.000 (21.215)
Eposide-(5000): [900/5000]	Time 0.427 (0.435)	Data 0.001 (0.001)	Loss 1.609 (1.653)	Prec@1 28.000 (21.237)
Eposide-(5000): [1000/5000]	Time 0.424 (0.434)	Data 0.000 (0.001)	Loss 1.610 (1.649)	Prec@1 24.000 (21.273)
Eposide-(5000): [1100/5000]	Time 0.473 (0.434)	Data 0.000 (0.001)	Loss 1.613 (1.647)	Prec@1 20.000 (21.299)
Eposide-(5000): [1200/5000]	Time 0.453 (0.433)	Data 0.000 (0.001)	Loss 1.610 (1.644)	Prec@1 22.667 (21.303)
Eposide-(5000): [1300/5000]	Time 0.420 (0.433)	Data 0.000 (0.001)	Loss 1.608 (1.641)	Prec@1 30.667 (21.320)
Eposide-(5000): [1400/5000]	Time 0.428 (0.433)	Data 0.000 (0.001)	Loss 1.611 (1.665)	Prec@1 20.000 (21.333)
Eposide-(5000): [1500/5000]	Time 0.431 (0.433)	Data 0.000 (0.001)	Loss 1.609 (1.661)	Prec@1 20.000 (21.311)
Eposide-(5000): [1600/5000]	Time 0.422 (0.433)	Data 0.000 (0.001)	Loss 1.610 (1.658)	Prec@1 20.000 (21.321)
Eposide-(5000): [1700/5000]	Time 0.431 (0.433)	Data 0.000 (0.001)	Loss 1.610 (1.655)	Prec@1 21.333 (21.314)
Eposide-(5000): [1800/5000]	Time 0.429 (0.433)	Data 0.000 (0.001)	Loss 1.610 (1.653)	Prec@1 20.000 (21.313)
Eposide-(5000): [1900/5000]	Time 0.434 (0.433)	Data 0.000 (0.001)	Loss 1.608 (1.651)	Prec@1 20.000 (21.337)
Eposide-(5000): [2000/5000]	Time 0.423 (0.433)	Data 0.000 (0.001)	Loss 1.609 (1.659)	Prec@1 20.000 (21.327)
Eposide-(5000): [2100/5000]	Time 0.424 (0.433)	Data 0.000 (0.001)	Loss 1.608 (1.656)	Prec@1 26.667 (21.342)
Eposide-(5000): [2200/5000]	Time 0.424 (0.433)	Data 0.000 (0.001)	Loss 1.609 (1.654)	Prec@1 24.000 (21.366)
Eposide-(5000): [2300/5000]	Time 0.442 (0.433)	Data 0.001 (0.001)	Loss 1.605 (1.655)	Prec@1 22.667 (21.390)
Eposide-(5000): [2400/5000]	Time 0.423 (0.433)	Data 0.000 (0.001)	Loss 1.610 (1.654)	Prec@1 20.000 (21.425)
Eposide-(5000): [2500/5000]	Time 0.452 (0.433)	Data 0.000 (0.001)	Loss 1.608 (1.652)	Prec@1 18.667 (21.445)
Eposide-(5000): [2600/5000]	Time 0.409 (0.433)	Data 0.000 (0.001)	Loss 1.612 (1.655)	Prec@1 21.333 (21.479)
Eposide-(5000): [2700/5000]	Time 0.435 (0.433)	Data 0.000 (0.001)	Loss 1.604 (1.653)	Prec@1 21.333 (21.496)
Eposide-(5000): [2800/5000]	Time 0.433 (0.433)	Data 0.000 (0.001)	Loss 1.619 (1.652)	Prec@1 25.333 (21.528)
Eposide-(5000): [2900/5000]	Time 0.434 (0.433)	Data 0.000 (0.001)	Loss 1.609 (1.673)	Prec@1 20.000 (21.551)
Eposide-(5000): [3000/5000]	Time 0.423 (0.433)	Data 0.000 (0.001)	Loss 1.609 (1.671)	Prec@1 21.333 (21.568)
Eposide-(5000): [3100/5000]	Time 0.483 (0.433)	Data 0.000 (0.000)	Loss 1.611 (1.670)	Prec@1 21.333 (21.582)
Eposide-(5000): [3200/5000]	Time 0.421 (0.433)	Data 0.000 (0.000)	Loss 1.605 (1.671)	Prec@1 29.333 (21.624)
Eposide-(5000): [3300/5000]	Time 0.429 (0.433)	Data 0.000 (0.000)	Loss 1.611 (1.669)	Prec@1 20.000 (21.638)
Eposide-(5000): [3400/5000]	Time 0.427 (0.433)	Data 0.000 (0.000)	Loss 1.612 (1.667)	Prec@1 20.000 (21.661)
Eposide-(5000): [3500/5000]	Time 0.416 (0.433)	Data 0.000 (0.000)	Loss 1.604 (1.667)	Prec@1 20.000 (21.674)
Eposide-(5000): [3600/5000]	Time 0.429 (0.433)	Data 0.000 (0.000)	Loss 1.607 (1.665)	Prec@1 26.667 (21.731)
Eposide-(5000): [3700/5000]	Time 0.455 (0.433)	Data 0.000 (0.000)	Loss 1.614 (1.664)	Prec@1 20.000 (21.769)
Eposide-(5000): [3800/5000]	Time 0.436 (0.433)	Data 0.000 (0.000)	Loss 1.600 (1.662)	Prec@1 24.000 (21.778)
Eposide-(5000): [3900/5000]	Time 0.432 (0.433)	Data 0.000 (0.000)	Loss 1.611 (1.661)	Prec@1 20.000 (21.799)
Eposide-(5000): [4000/5000]	Time 0.424 (0.433)	Data 0.000 (0.000)	Loss 1.609 (1.660)	Prec@1 24.000 (21.827)
Eposide-(5000): [4100/5000]	Time 0.444 (0.433)	Data 0.000 (0.000)	Loss 1.614 (1.659)	Prec@1 20.000 (21.850)
Eposide-(5000): [4200/5000]	Time 0.408 (0.433)	Data 0.000 (0.000)	Loss 1.612 (1.658)	Prec@1 21.333 (21.851)
Eposide-(5000): [4300/5000]	Time 0.422 (0.433)	Data 0.000 (0.000)	Loss 1.614 (1.657)	Prec@1 24.000 (21.882)
Eposide-(5000): [4400/5000]	Time 0.424 (0.433)	Data 0.000 (0.000)	Loss 1.613 (1.658)	Prec@1 20.000 (21.907)
Eposide-(5000): [4500/5000]	Time 0.457 (0.433)	Data 0.000 (0.000)	Loss 1.616 (1.657)	Prec@1 20.000 (21.940)
Eposide-(5000): [4600/5000]	Time 0.422 (0.433)	Data 0.000 (0.000)	Loss 1.613 (1.656)	Prec@1 24.000 (21.956)
Eposide-(5000): [4700/5000]	Time 0.437 (0.433)	Data 0.000 (0.000)	Loss 1.607 (1.658)	Prec@1 26.667 (21.963)
Eposide-(5000): [4800/5000]	Time 0.425 (0.433)	Data 0.000 (0.000)	Loss 1.595 (1.657)	Prec@1 20.000 (21.980)
Eposide-(5000): [4900/5000]	Time 0.460 (0.433)	Data 0.000 (0.000)	Loss 1.605 (1.657)	Prec@1 20.000 (21.997)
============ validation on the val set ============
Test-(1): [100/500]	Time 0.253 (0.278)	Loss 1.608 (1.611)	Prec@1 20.000 (20.884)
Test-(1): [200/500]	Time 0.258 (0.273)	Loss 1.614 (1.611)	Prec@1 20.000 (21.055)
Test-(1): [300/500]	Time 0.261 (0.272)	Loss 1.608 (1.611)	Prec@1 28.000 (21.068)
Test-(1): [400/500]	Time 0.300 (0.271)	Loss 1.601 (1.611)	Prec@1 24.000 (20.978)
 * Prec@1 21.013 Best_prec1 20.205
============ Testing on the test set ============
Test-(1): [100/500]	Time 0.255 (0.279)	Loss 1.617 (1.614)	Prec@1 20.000 (20.541)
Test-(1): [200/500]	Time 0.260 (0.274)	Loss 1.610 (1.614)	Prec@1 29.333 (20.385)
Test-(1): [300/500]	Time 0.260 (0.272)	Loss 1.617 (1.614)	Prec@1 20.000 (20.456)
Test-(1): [400/500]	Time 0.257 (0.270)	Loss 1.631 (1.614)	Prec@1 20.000 (20.456)
 * Prec@1 20.475 Best_prec1 21.013
===================================== Epoch 2 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(10000): [100/5000]	Time 0.442 (0.445)	Data 0.000 (0.010)	Loss 1.622 (1.658)	Prec@1 18.667 (22.469)
Eposide-(10000): [200/5000]	Time 0.463 (0.439)	Data 0.000 (0.005)	Loss 1.613 (1.633)	Prec@1 29.333 (22.978)
Eposide-(10000): [300/5000]	Time 0.437 (0.437)	Data 0.000 (0.004)	Loss 1.612 (1.633)	Prec@1 24.000 (22.893)
Eposide-(10000): [400/5000]	Time 0.420 (0.437)	Data 0.000 (0.003)	Loss 1.567 (1.633)	Prec@1 28.000 (22.790)
Eposide-(10000): [500/5000]	Time 0.439 (0.437)	Data 0.000 (0.002)	Loss 1.617 (1.630)	Prec@1 21.333 (22.683)
Eposide-(10000): [600/5000]	Time 0.446 (0.437)	Data 0.000 (0.002)	Loss 1.608 (1.694)	Prec@1 20.000 (22.762)
Eposide-(10000): [700/5000]	Time 0.445 (0.436)	Data 0.000 (0.002)	Loss 1.611 (1.686)	Prec@1 22.667 (22.786)
Eposide-(10000): [800/5000]	Time 0.484 (0.436)	Data 0.000 (0.002)	Loss 1.604 (1.677)	Prec@1 32.000 (22.858)
Eposide-(10000): [900/5000]	Time 0.436 (0.436)	Data 0.000 (0.001)	Loss 1.607 (1.673)	Prec@1 22.667 (22.821)
Eposide-(10000): [1000/5000]	Time 0.425 (0.436)	Data 0.000 (0.001)	Loss 1.614 (1.668)	Prec@1 22.667 (22.807)
Eposide-(10000): [1100/5000]	Time 0.409 (0.436)	Data 0.000 (0.001)	Loss 1.618 (1.668)	Prec@1 20.000 (22.820)
Eposide-(10000): [1200/5000]	Time 0.426 (0.435)	Data 0.000 (0.001)	Loss 1.605 (1.663)	Prec@1 20.000 (22.820)
Eposide-(10000): [1300/5000]	Time 0.440 (0.435)	Data 0.000 (0.001)	Loss 1.604 (1.658)	Prec@1 30.667 (22.823)
Eposide-(10000): [1400/5000]	Time 0.450 (0.435)	Data 0.000 (0.001)	Loss 1.538 (1.655)	Prec@1 24.000 (22.808)
Eposide-(10000): [1500/5000]	Time 0.465 (0.434)	Data 0.000 (0.001)	Loss 1.619 (1.652)	Prec@1 24.000 (22.771)
Eposide-(10000): [1600/5000]	Time 0.429 (0.434)	Data 0.000 (0.001)	Loss 1.615 (1.651)	Prec@1 20.000 (22.800)
Eposide-(10000): [1700/5000]	Time 0.414 (0.434)	Data 0.000 (0.001)	Loss 1.610 (1.651)	Prec@1 26.667 (22.783)
Eposide-(10000): [1800/5000]	Time 0.416 (0.434)	Data 0.000 (0.001)	Loss 1.607 (1.649)	Prec@1 30.667 (22.812)
Eposide-(10000): [1900/5000]	Time 0.410 (0.434)	Data 0.000 (0.001)	Loss 1.607 (1.650)	Prec@1 24.000 (22.824)
Eposide-(10000): [2000/5000]	Time 0.414 (0.434)	Data 0.000 (0.001)	Loss 1.611 (1.649)	Prec@1 20.000 (22.855)
Eposide-(10000): [2100/5000]	Time 0.416 (0.433)	Data 0.000 (0.001)	Loss 1.612 (1.647)	Prec@1 21.333 (22.857)
Eposide-(10000): [2200/5000]	Time 0.424 (0.434)	Data 0.000 (0.001)	Loss 1.601 (1.645)	Prec@1 21.333 (22.911)
Eposide-(10000): [2300/5000]	Time 0.446 (0.433)	Data 0.000 (0.001)	Loss 1.608 (1.643)	Prec@1 26.667 (22.905)
Eposide-(10000): [2400/5000]	Time 0.426 (0.433)	Data 0.000 (0.001)	Loss 1.613 (1.642)	Prec@1 21.333 (22.903)
Eposide-(10000): [2500/5000]	Time 0.431 (0.433)	Data 0.000 (0.001)	Loss 1.611 (1.642)	Prec@1 20.000 (22.892)
Eposide-(10000): [2600/5000]	Time 0.464 (0.433)	Data 0.001 (0.001)	Loss 1.603 (1.644)	Prec@1 21.333 (22.871)
Eposide-(10000): [2700/5000]	Time 0.415 (0.433)	Data 0.000 (0.001)	Loss 1.605 (1.644)	Prec@1 30.667 (22.873)
Eposide-(10000): [2800/5000]	Time 0.469 (0.433)	Data 0.000 (0.001)	Loss 1.610 (1.643)	Prec@1 20.000 (22.853)
Eposide-(10000): [2900/5000]	Time 0.424 (0.433)	Data 0.000 (0.001)	Loss 1.608 (1.641)	Prec@1 20.000 (22.839)
Eposide-(10000): [3000/5000]	Time 0.414 (0.433)	Data 0.000 (0.001)	Loss 1.612 (1.643)	Prec@1 20.000 (22.820)
Eposide-(10000): [3100/5000]	Time 0.431 (0.433)	Data 0.000 (0.001)	Loss 1.616 (1.642)	Prec@1 26.667 (22.827)
Eposide-(10000): [3200/5000]	Time 0.513 (0.433)	Data 0.000 (0.001)	Loss 1.605 (1.643)	Prec@1 26.667 (22.827)
Eposide-(10000): [3300/5000]	Time 0.424 (0.433)	Data 0.000 (0.001)	Loss 1.603 (1.646)	Prec@1 22.667 (22.816)
Eposide-(10000): [3400/5000]	Time 0.446 (0.433)	Data 0.000 (0.001)	Loss 1.620 (1.645)	Prec@1 20.000 (22.811)
Eposide-(10000): [3500/5000]	Time 0.423 (0.433)	Data 0.000 (0.001)	Loss 1.598 (1.645)	Prec@1 21.333 (22.803)
Eposide-(10000): [3600/5000]	Time 0.480 (0.433)	Data 0.000 (0.001)	Loss 1.612 (1.649)	Prec@1 21.333 (22.798)
Eposide-(10000): [3700/5000]	Time 0.424 (0.433)	Data 0.000 (0.001)	Loss 1.604 (1.648)	Prec@1 20.000 (22.777)
Eposide-(10000): [3800/5000]	Time 0.432 (0.433)	Data 0.000 (0.001)	Loss 1.605 (1.647)	Prec@1 20.000 (22.759)
Eposide-(10000): [3900/5000]	Time 0.416 (0.433)	Data 0.000 (0.001)	Loss 1.645 (1.651)	Prec@1 26.667 (22.769)
Eposide-(10000): [4000/5000]	Time 0.434 (0.433)	Data 0.000 (0.001)	Loss 1.617 (1.649)	Prec@1 24.000 (22.777)
Eposide-(10000): [4100/5000]	Time 0.448 (0.433)	Data 0.000 (0.001)	Loss 1.611 (1.659)	Prec@1 20.000 (22.769)
Eposide-(10000): [4200/5000]	Time 0.425 (0.433)	Data 0.000 (0.000)	Loss 1.606 (1.658)	Prec@1 28.000 (22.766)
Eposide-(10000): [4300/5000]	Time 0.455 (0.433)	Data 0.000 (0.000)	Loss 1.605 (1.660)	Prec@1 20.000 (22.774)
Eposide-(10000): [4400/5000]	Time 0.430 (0.433)	Data 0.000 (0.000)	Loss 2.659 (1.659)	Prec@1 22.667 (22.765)
Eposide-(10000): [4500/5000]	Time 0.502 (0.433)	Data 0.000 (0.000)	Loss 1.601 (1.658)	Prec@1 36.000 (22.783)
Eposide-(10000): [4600/5000]	Time 0.440 (0.433)	Data 0.000 (0.000)	Loss 1.614 (1.657)	Prec@1 24.000 (22.785)
Eposide-(10000): [4700/5000]	Time 0.431 (0.433)	Data 0.000 (0.000)	Loss 1.584 (1.657)	Prec@1 28.000 (22.805)
Eposide-(10000): [4800/5000]	Time 0.426 (0.433)	Data 0.000 (0.000)	Loss 1.592 (1.656)	Prec@1 37.333 (22.814)
Eposide-(10000): [4900/5000]	Time 0.418 (0.433)	Data 0.000 (0.000)	Loss 1.613 (1.656)	Prec@1 22.667 (22.810)
============ validation on the val set ============
Test-(2): [100/500]	Time 0.266 (0.275)	Loss 1.597 (1.614)	Prec@1 22.667 (22.561)
Test-(2): [200/500]	Time 0.264 (0.271)	Loss 1.623 (1.615)	Prec@1 17.333 (22.335)
Test-(2): [300/500]	Time 0.261 (0.270)	Loss 1.615 (1.615)	Prec@1 26.667 (22.392)
Test-(2): [400/500]	Time 0.272 (0.269)	Loss 1.606 (1.615)	Prec@1 18.667 (22.354)
 * Prec@1 22.267 Best_prec1 21.013
============ Testing on the test set ============
Test-(2): [100/500]	Time 0.262 (0.278)	Loss 1.622 (1.619)	Prec@1 20.000 (21.967)
Test-(2): [200/500]	Time 0.268 (0.273)	Loss 1.619 (1.618)	Prec@1 22.667 (22.090)
Test-(2): [300/500]	Time 0.267 (0.271)	Loss 1.615 (1.618)	Prec@1 20.000 (22.122)
Test-(2): [400/500]	Time 0.284 (0.271)	Loss 1.614 (1.618)	Prec@1 21.333 (22.101)
 * Prec@1 22.096 Best_prec1 22.267
===================================== Epoch 3 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(15000): [100/5000]	Time 0.434 (0.445)	Data 0.000 (0.008)	Loss 1.605 (1.625)	Prec@1 22.667 (23.815)
Eposide-(15000): [200/5000]	Time 0.434 (0.439)	Data 0.000 (0.004)	Loss 1.600 (1.683)	Prec@1 20.000 (23.496)
Eposide-(15000): [300/5000]	Time 0.430 (0.435)	Data 0.000 (0.003)	Loss 1.605 (1.657)	Prec@1 18.667 (23.353)
Eposide-(15000): [400/5000]	Time 0.458 (0.434)	Data 0.000 (0.002)	Loss 1.601 (1.658)	Prec@1 25.333 (23.242)
Eposide-(15000): [500/5000]	Time 0.441 (0.433)	Data 0.000 (0.002)	Loss 1.585 (1.676)	Prec@1 32.000 (23.327)
Eposide-(15000): [600/5000]	Time 0.428 (0.433)	Data 0.000 (0.002)	Loss 1.596 (1.672)	Prec@1 33.333 (23.312)
Eposide-(15000): [700/5000]	Time 0.547 (0.432)	Data 0.000 (0.002)	Loss 1.412 (1.663)	Prec@1 29.333 (23.285)
Eposide-(15000): [800/5000]	Time 0.426 (0.432)	Data 0.000 (0.001)	Loss 1.609 (1.664)	Prec@1 20.000 (23.236)
Eposide-(15000): [900/5000]	Time 0.408 (0.432)	Data 0.000 (0.001)	Loss 1.477 (1.657)	Prec@1 29.333 (23.192)
Eposide-(15000): [1000/5000]	Time 0.436 (0.431)	Data 0.000 (0.001)	Loss 1.611 (1.656)	Prec@1 20.000 (23.177)
Eposide-(15000): [1100/5000]	Time 0.418 (0.431)	Data 0.000 (0.001)	Loss 1.611 (1.657)	Prec@1 24.000 (23.238)
Eposide-(15000): [1200/5000]	Time 0.424 (0.431)	Data 0.000 (0.001)	Loss 1.602 (1.653)	Prec@1 29.333 (23.233)
Eposide-(15000): [1300/5000]	Time 0.453 (0.431)	Data 0.000 (0.001)	Loss 1.600 (1.650)	Prec@1 29.333 (23.236)
Eposide-(15000): [1400/5000]	Time 0.421 (0.431)	Data 0.000 (0.001)	Loss 1.605 (1.647)	Prec@1 24.000 (23.249)
Eposide-(15000): [1500/5000]	Time 0.448 (0.431)	Data 0.000 (0.001)	Loss 1.612 (1.644)	Prec@1 25.333 (23.268)
Eposide-(15000): [1600/5000]	Time 0.453 (0.431)	Data 0.000 (0.001)	Loss 1.602 (1.645)	Prec@1 21.333 (23.266)
Eposide-(15000): [1700/5000]	Time 0.437 (0.431)	Data 0.000 (0.001)	Loss 1.574 (1.643)	Prec@1 22.667 (23.310)
Eposide-(15000): [1800/5000]	Time 0.411 (0.431)	Data 0.000 (0.001)	Loss 1.565 (1.644)	Prec@1 28.000 (23.350)
Eposide-(15000): [1900/5000]	Time 0.591 (0.431)	Data 0.000 (0.001)	Loss 1.597 (1.641)	Prec@1 20.000 (23.373)
Eposide-(15000): [2000/5000]	Time 0.426 (0.431)	Data 0.000 (0.001)	Loss 1.614 (1.641)	Prec@1 20.000 (23.374)
Eposide-(15000): [2100/5000]	Time 0.412 (0.432)	Data 0.000 (0.001)	Loss 1.584 (1.645)	Prec@1 26.667 (23.412)
Eposide-(15000): [2200/5000]	Time 0.409 (0.432)	Data 0.000 (0.001)	Loss 1.611 (1.646)	Prec@1 25.333 (23.462)
Eposide-(15000): [2300/5000]	Time 0.487 (0.432)	Data 0.001 (0.001)	Loss 1.605 (1.645)	Prec@1 20.000 (23.506)
Eposide-(15000): [2400/5000]	Time 0.424 (0.432)	Data 0.000 (0.001)	Loss 2.788 (1.644)	Prec@1 25.333 (23.535)
Eposide-(15000): [2500/5000]	Time 0.429 (0.432)	Data 0.000 (0.001)	Loss 1.607 (1.644)	Prec@1 20.000 (23.542)
Eposide-(15000): [2600/5000]	Time 0.448 (0.432)	Data 0.000 (0.001)	Loss 1.594 (1.642)	Prec@1 26.667 (23.554)
Eposide-(15000): [2700/5000]	Time 0.573 (0.432)	Data 0.000 (0.001)	Loss 1.604 (1.641)	Prec@1 25.333 (23.550)
Eposide-(15000): [2800/5000]	Time 0.452 (0.432)	Data 0.000 (0.001)	Loss 1.676 (1.640)	Prec@1 18.667 (23.552)
Eposide-(15000): [2900/5000]	Time 0.443 (0.432)	Data 0.000 (0.001)	Loss 1.597 (1.638)	Prec@1 25.333 (23.579)
Eposide-(15000): [3000/5000]	Time 0.433 (0.432)	Data 0.000 (0.001)	Loss 11.610 (1.641)	Prec@1 20.000 (23.583)
Eposide-(15000): [3100/5000]	Time 0.439 (0.432)	Data 0.000 (0.001)	Loss 1.577 (1.640)	Prec@1 20.000 (23.606)
Eposide-(15000): [3200/5000]	Time 0.416 (0.432)	Data 0.000 (0.001)	Loss 1.562 (1.639)	Prec@1 24.000 (23.625)
Eposide-(15000): [3300/5000]	Time 0.459 (0.432)	Data 0.000 (0.001)	Loss 1.585 (1.638)	Prec@1 29.333 (23.640)
Eposide-(15000): [3400/5000]	Time 0.434 (0.432)	Data 0.000 (0.001)	Loss 1.614 (1.640)	Prec@1 20.000 (23.630)
Eposide-(15000): [3500/5000]	Time 0.425 (0.432)	Data 0.000 (0.001)	Loss 1.606 (1.639)	Prec@1 29.333 (23.632)
Eposide-(15000): [3600/5000]	Time 0.416 (0.432)	Data 0.000 (0.001)	Loss 1.611 (1.638)	Prec@1 20.000 (23.651)
Eposide-(15000): [3700/5000]	Time 0.441 (0.432)	Data 0.000 (0.001)	Loss 1.558 (1.637)	Prec@1 20.000 (23.665)
Eposide-(15000): [3800/5000]	Time 0.421 (0.432)	Data 0.000 (0.000)	Loss 1.624 (1.636)	Prec@1 20.000 (23.686)
Eposide-(15000): [3900/5000]	Time 0.436 (0.432)	Data 0.000 (0.000)	Loss 1.621 (1.635)	Prec@1 20.000 (23.699)
Eposide-(15000): [4000/5000]	Time 0.455 (0.432)	Data 0.000 (0.000)	Loss 1.598 (1.635)	Prec@1 24.000 (23.712)
Eposide-(15000): [4100/5000]	Time 0.426 (0.432)	Data 0.000 (0.000)	Loss 1.606 (1.634)	Prec@1 20.000 (23.712)
Eposide-(15000): [4200/5000]	Time 0.420 (0.433)	Data 0.000 (0.000)	Loss 1.580 (1.638)	Prec@1 32.000 (23.734)
Eposide-(15000): [4300/5000]	Time 0.427 (0.433)	Data 0.000 (0.000)	Loss 1.610 (1.638)	Prec@1 20.000 (23.727)
Eposide-(15000): [4400/5000]	Time 0.433 (0.432)	Data 0.000 (0.000)	Loss 1.599 (1.637)	Prec@1 20.000 (23.716)
Eposide-(15000): [4500/5000]	Time 0.422 (0.432)	Data 0.000 (0.000)	Loss 1.596 (1.636)	Prec@1 26.667 (23.731)
Eposide-(15000): [4600/5000]	Time 0.427 (0.432)	Data 0.000 (0.000)	Loss 1.589 (1.636)	Prec@1 30.667 (23.763)
Eposide-(15000): [4700/5000]	Time 0.454 (0.432)	Data 0.000 (0.000)	Loss 1.575 (1.636)	Prec@1 28.000 (23.794)
Eposide-(15000): [4800/5000]	Time 0.431 (0.432)	Data 0.000 (0.000)	Loss 1.462 (1.637)	Prec@1 30.667 (23.815)
Eposide-(15000): [4900/5000]	Time 0.429 (0.432)	Data 0.000 (0.000)	Loss 1.570 (1.636)	Prec@1 26.667 (23.813)
============ validation on the val set ============
Test-(3): [100/500]	Time 0.252 (0.281)	Loss 1.585 (1.701)	Prec@1 24.000 (21.888)
Test-(3): [200/500]	Time 0.261 (0.274)	Loss 1.547 (1.706)	Prec@1 24.000 (21.566)
Test-(3): [300/500]	Time 0.265 (0.272)	Loss 1.761 (1.713)	Prec@1 28.000 (21.457)
Test-(3): [400/500]	Time 0.261 (0.271)	Loss 1.615 (1.705)	Prec@1 20.000 (21.629)
 * Prec@1 21.813 Best_prec1 22.267
============ Testing on the test set ============
Test-(3): [100/500]	Time 0.246 (0.278)	Loss 1.648 (1.639)	Prec@1 20.000 (21.149)
Test-(3): [200/500]	Time 0.250 (0.272)	Loss 1.608 (1.634)	Prec@1 20.000 (21.148)
Test-(3): [300/500]	Time 0.278 (0.271)	Loss 1.613 (1.638)	Prec@1 24.000 (21.107)
Test-(3): [400/500]	Time 0.271 (0.271)	Loss 1.660 (1.639)	Prec@1 20.000 (21.044)
 * Prec@1 20.957 Best_prec1 22.267
===================================== Epoch 4 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(20000): [100/5000]	Time 0.425 (0.443)	Data 0.000 (0.007)	Loss 1.623 (1.609)	Prec@1 20.000 (25.003)
Eposide-(20000): [200/5000]	Time 0.429 (0.437)	Data 0.000 (0.004)	Loss 1.610 (1.607)	Prec@1 20.000 (25.141)
Eposide-(20000): [300/5000]	Time 0.418 (0.436)	Data 0.000 (0.002)	Loss 1.535 (1.601)	Prec@1 25.333 (25.249)
Eposide-(20000): [400/5000]	Time 0.427 (0.435)	Data 0.000 (0.002)	Loss 1.570 (1.602)	Prec@1 20.000 (24.921)
Eposide-(20000): [500/5000]	Time 0.414 (0.434)	Data 0.000 (0.002)	Loss 1.682 (1.604)	Prec@1 32.000 (24.900)
Eposide-(20000): [600/5000]	Time 0.453 (0.434)	Data 0.000 (0.001)	Loss 1.624 (1.603)	Prec@1 28.000 (24.854)
Eposide-(20000): [700/5000]	Time 0.423 (0.434)	Data 0.000 (0.001)	Loss 1.613 (1.628)	Prec@1 21.333 (24.987)
Eposide-(20000): [800/5000]	Time 0.463 (0.433)	Data 0.000 (0.001)	Loss 1.570 (1.626)	Prec@1 22.667 (24.934)
Eposide-(20000): [900/5000]	Time 0.426 (0.434)	Data 0.000 (0.001)	Loss 1.614 (1.621)	Prec@1 29.333 (24.993)
Eposide-(20000): [1000/5000]	Time 0.425 (0.433)	Data 0.000 (0.001)	Loss 1.609 (1.619)	Prec@1 24.000 (24.907)
Eposide-(20000): [1100/5000]	Time 0.426 (0.433)	Data 0.000 (0.001)	Loss 1.621 (1.620)	Prec@1 24.000 (24.963)
Eposide-(20000): [1200/5000]	Time 0.412 (0.433)	Data 0.000 (0.001)	Loss 1.613 (1.624)	Prec@1 24.000 (25.029)
Eposide-(20000): [1300/5000]	Time 0.436 (0.433)	Data 0.000 (0.001)	Loss 1.585 (1.622)	Prec@1 33.333 (25.000)
Eposide-(20000): [1400/5000]	Time 0.424 (0.433)	Data 0.000 (0.001)	Loss 1.612 (1.621)	Prec@1 21.333 (24.965)
Eposide-(20000): [1500/5000]	Time 0.417 (0.432)	Data 0.000 (0.001)	Loss 1.604 (1.626)	Prec@1 24.000 (24.993)
Eposide-(20000): [1600/5000]	Time 0.424 (0.432)	Data 0.000 (0.001)	Loss 1.613 (1.633)	Prec@1 21.333 (24.997)
Eposide-(20000): [1700/5000]	Time 0.425 (0.432)	Data 0.000 (0.001)	Loss 1.615 (1.631)	Prec@1 24.000 (25.021)
Eposide-(20000): [1800/5000]	Time 0.413 (0.432)	Data 0.000 (0.001)	Loss 1.607 (1.631)	Prec@1 29.333 (25.035)
Eposide-(20000): [1900/5000]	Time 0.425 (0.432)	Data 0.000 (0.001)	Loss 1.548 (1.642)	Prec@1 20.000 (25.049)
Eposide-(20000): [2000/5000]	Time 0.449 (0.432)	Data 0.000 (0.001)	Loss 1.638 (1.641)	Prec@1 20.000 (25.054)
Eposide-(20000): [2100/5000]	Time 0.438 (0.432)	Data 0.000 (0.001)	Loss 1.673 (1.639)	Prec@1 20.000 (25.059)
Eposide-(20000): [2200/5000]	Time 0.426 (0.432)	Data 0.000 (0.001)	Loss 1.592 (1.637)	Prec@1 30.667 (25.040)
Eposide-(20000): [2300/5000]	Time 0.412 (0.432)	Data 0.000 (0.001)	Loss 1.601 (1.641)	Prec@1 21.333 (25.010)
Eposide-(20000): [2400/5000]	Time 0.446 (0.432)	Data 0.000 (0.001)	Loss 1.623 (1.639)	Prec@1 30.667 (25.023)
Eposide-(20000): [2500/5000]	Time 0.435 (0.432)	Data 0.000 (0.001)	Loss 1.641 (1.638)	Prec@1 21.333 (24.992)
Eposide-(20000): [2600/5000]	Time 0.431 (0.432)	Data 0.000 (0.000)	Loss 1.585 (1.636)	Prec@1 36.000 (25.008)
Eposide-(20000): [2700/5000]	Time 0.413 (0.432)	Data 0.000 (0.000)	Loss 1.614 (1.634)	Prec@1 22.667 (25.034)
Eposide-(20000): [2800/5000]	Time 0.438 (0.432)	Data 0.000 (0.000)	Loss 1.611 (1.633)	Prec@1 20.000 (25.024)
Eposide-(20000): [2900/5000]	Time 0.410 (0.432)	Data 0.000 (0.000)	Loss 1.556 (1.632)	Prec@1 29.333 (25.024)
Eposide-(20000): [3000/5000]	Time 0.412 (0.432)	Data 0.000 (0.000)	Loss 1.592 (1.634)	Prec@1 34.667 (25.007)
Eposide-(20000): [3100/5000]	Time 0.468 (0.432)	Data 0.000 (0.000)	Loss 2.011 (1.634)	Prec@1 30.667 (25.039)
Eposide-(20000): [3200/5000]	Time 0.431 (0.432)	Data 0.000 (0.000)	Loss 1.572 (1.633)	Prec@1 37.333 (25.059)
Eposide-(20000): [3300/5000]	Time 0.408 (0.432)	Data 0.000 (0.000)	Loss 1.539 (1.636)	Prec@1 25.333 (25.081)
Eposide-(20000): [3400/5000]	Time 0.428 (0.432)	Data 0.000 (0.000)	Loss 1.620 (1.635)	Prec@1 18.667 (25.097)
Eposide-(20000): [3500/5000]	Time 0.414 (0.432)	Data 0.000 (0.000)	Loss 1.600 (1.633)	Prec@1 22.667 (25.064)
Eposide-(20000): [3600/5000]	Time 0.415 (0.432)	Data 0.000 (0.000)	Loss 1.577 (1.632)	Prec@1 24.000 (25.082)
Eposide-(20000): [3700/5000]	Time 0.409 (0.432)	Data 0.000 (0.000)	Loss 1.590 (1.636)	Prec@1 25.333 (25.091)
Eposide-(20000): [3800/5000]	Time 0.442 (0.432)	Data 0.000 (0.000)	Loss 1.614 (1.635)	Prec@1 21.333 (25.101)
Eposide-(20000): [3900/5000]	Time 0.433 (0.432)	Data 0.000 (0.000)	Loss 1.589 (1.634)	Prec@1 25.333 (25.095)
Eposide-(20000): [4000/5000]	Time 0.485 (0.432)	Data 0.000 (0.000)	Loss 1.473 (1.635)	Prec@1 26.667 (25.096)
Eposide-(20000): [4100/5000]	Time 0.441 (0.432)	Data 0.000 (0.000)	Loss 1.909 (1.634)	Prec@1 21.333 (25.119)
Eposide-(20000): [4200/5000]	Time 0.416 (0.432)	Data 0.000 (0.000)	Loss 1.641 (1.633)	Prec@1 20.000 (25.138)
Eposide-(20000): [4300/5000]	Time 0.441 (0.432)	Data 0.000 (0.000)	Loss 1.509 (1.633)	Prec@1 29.333 (25.163)
Eposide-(20000): [4400/5000]	Time 0.427 (0.432)	Data 0.000 (0.000)	Loss 1.574 (1.632)	Prec@1 34.667 (25.172)
Eposide-(20000): [4500/5000]	Time 0.423 (0.432)	Data 0.000 (0.000)	Loss 1.575 (1.631)	Prec@1 34.667 (25.173)
Eposide-(20000): [4600/5000]	Time 0.430 (0.432)	Data 0.000 (0.000)	Loss 1.488 (1.631)	Prec@1 33.333 (25.186)
Eposide-(20000): [4700/5000]	Time 0.432 (0.432)	Data 0.000 (0.000)	Loss 1.598 (1.630)	Prec@1 20.000 (25.185)
Eposide-(20000): [4800/5000]	Time 0.455 (0.432)	Data 0.000 (0.000)	Loss 1.478 (1.629)	Prec@1 29.333 (25.188)
Eposide-(20000): [4900/5000]	Time 0.419 (0.432)	Data 0.000 (0.000)	Loss 1.591 (1.629)	Prec@1 32.000 (25.212)
============ validation on the val set ============
Test-(4): [100/500]	Time 0.261 (0.280)	Loss 1.573 (1.616)	Prec@1 29.333 (21.941)
Test-(4): [200/500]	Time 0.254 (0.274)	Loss 1.580 (1.615)	Prec@1 28.000 (22.441)
Test-(4): [300/500]	Time 0.255 (0.271)	Loss 1.605 (1.618)	Prec@1 20.000 (22.144)
Test-(4): [400/500]	Time 0.260 (0.270)	Loss 1.641 (1.621)	Prec@1 20.000 (22.218)
 * Prec@1 22.160 Best_prec1 22.267
============ Testing on the test set ============
Test-(4): [100/500]	Time 0.289 (0.275)	Loss 1.621 (1.630)	Prec@1 20.000 (20.884)
Test-(4): [200/500]	Time 0.278 (0.270)	Loss 1.617 (1.630)	Prec@1 22.667 (20.769)
Test-(4): [300/500]	Time 0.252 (0.270)	Loss 1.615 (1.631)	Prec@1 20.000 (20.828)
Test-(4): [400/500]	Time 0.249 (0.269)	Loss 1.656 (1.631)	Prec@1 20.000 (20.838)
 * Prec@1 20.861 Best_prec1 22.267
===================================== Epoch 5 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(25000): [100/5000]	Time 0.426 (0.441)	Data 0.000 (0.009)	Loss 1.600 (1.631)	Prec@1 20.000 (25.452)
Eposide-(25000): [200/5000]	Time 0.425 (0.433)	Data 0.000 (0.004)	Loss 1.579 (1.641)	Prec@1 25.333 (26.056)
Eposide-(25000): [300/5000]	Time 0.451 (0.432)	Data 0.000 (0.003)	Loss 1.592 (1.632)	Prec@1 20.000 (25.652)
Eposide-(25000): [400/5000]	Time 0.431 (0.432)	Data 0.000 (0.002)	Loss 1.614 (1.622)	Prec@1 20.000 (25.593)
Eposide-(25000): [500/5000]	Time 0.432 (0.432)	Data 0.000 (0.002)	Loss 1.650 (1.622)	Prec@1 20.000 (25.935)
Eposide-(25000): [600/5000]	Time 0.551 (0.432)	Data 0.001 (0.002)	Loss 1.609 (1.617)	Prec@1 21.333 (25.915)
Eposide-(25000): [700/5000]	Time 0.412 (0.431)	Data 0.000 (0.001)	Loss 1.544 (1.614)	Prec@1 22.667 (25.731)
Eposide-(25000): [800/5000]	Time 0.444 (0.431)	Data 0.000 (0.001)	Loss 1.405 (1.610)	Prec@1 37.333 (25.758)
Eposide-(25000): [900/5000]	Time 0.424 (0.431)	Data 0.000 (0.001)	Loss 1.575 (1.640)	Prec@1 25.333 (25.739)
Eposide-(25000): [1000/5000]	Time 0.428 (0.430)	Data 0.000 (0.001)	Loss 1.465 (1.634)	Prec@1 30.667 (25.732)
Eposide-(25000): [1100/5000]	Time 0.444 (0.430)	Data 0.000 (0.001)	Loss 1.588 (1.630)	Prec@1 26.667 (25.826)
Eposide-(25000): [1200/5000]	Time 0.418 (0.430)	Data 0.000 (0.001)	Loss 1.647 (1.627)	Prec@1 21.333 (25.836)
Eposide-(25000): [1300/5000]	Time 0.437 (0.430)	Data 0.000 (0.001)	Loss 1.592 (1.624)	Prec@1 30.667 (25.862)
Eposide-(25000): [1400/5000]	Time 0.425 (0.430)	Data 0.000 (0.001)	Loss 1.584 (1.622)	Prec@1 22.667 (25.815)
Eposide-(25000): [1500/5000]	Time 0.468 (0.430)	Data 0.000 (0.001)	Loss 1.541 (1.621)	Prec@1 33.333 (25.829)
Eposide-(25000): [1600/5000]	Time 0.437 (0.431)	Data 0.000 (0.001)	Loss 1.597 (1.619)	Prec@1 26.667 (25.828)
Eposide-(25000): [1700/5000]	Time 0.426 (0.430)	Data 0.000 (0.001)	Loss 1.575 (1.617)	Prec@1 29.333 (25.779)
Eposide-(25000): [1800/5000]	Time 0.425 (0.430)	Data 0.000 (0.001)	Loss 1.602 (1.616)	Prec@1 20.000 (25.790)
Eposide-(25000): [1900/5000]	Time 0.427 (0.430)	Data 0.000 (0.001)	Loss 1.601 (1.614)	Prec@1 21.333 (25.833)
Eposide-(25000): [2000/5000]	Time 0.430 (0.430)	Data 0.000 (0.001)	Loss 1.577 (1.612)	Prec@1 21.333 (25.862)
Eposide-(25000): [2100/5000]	Time 0.424 (0.430)	Data 0.000 (0.001)	Loss 1.603 (1.611)	Prec@1 26.667 (25.891)
Eposide-(25000): [2200/5000]	Time 0.426 (0.430)	Data 0.000 (0.001)	Loss 1.583 (1.613)	Prec@1 25.333 (25.866)
Eposide-(25000): [2300/5000]	Time 0.413 (0.430)	Data 0.000 (0.001)	Loss 1.573 (1.611)	Prec@1 25.333 (25.900)
Eposide-(25000): [2400/5000]	Time 0.437 (0.430)	Data 0.000 (0.001)	Loss 1.622 (1.610)	Prec@1 21.333 (25.913)
Eposide-(25000): [2500/5000]	Time 0.441 (0.430)	Data 0.000 (0.001)	Loss 1.631 (1.609)	Prec@1 25.333 (25.938)
Eposide-(25000): [2600/5000]	Time 0.416 (0.430)	Data 0.000 (0.001)	Loss 1.649 (1.607)	Prec@1 24.000 (25.962)
Eposide-(25000): [2700/5000]	Time 0.425 (0.431)	Data 0.000 (0.001)	Loss 1.558 (1.606)	Prec@1 32.000 (26.023)
Eposide-(25000): [2800/5000]	Time 0.429 (0.431)	Data 0.000 (0.001)	Loss 1.573 (1.605)	Prec@1 28.000 (26.044)
Eposide-(25000): [2900/5000]	Time 0.429 (0.431)	Data 0.000 (0.001)	Loss 1.674 (1.604)	Prec@1 26.667 (26.051)
Eposide-(25000): [3000/5000]	Time 0.413 (0.431)	Data 0.000 (0.001)	Loss 1.600 (1.603)	Prec@1 21.333 (26.079)
Eposide-(25000): [3100/5000]	Time 0.429 (0.432)	Data 0.000 (0.001)	Loss 1.738 (1.602)	Prec@1 32.000 (26.139)
Eposide-(25000): [3200/5000]	Time 0.421 (0.432)	Data 0.000 (0.001)	Loss 1.576 (1.601)	Prec@1 28.000 (26.146)
Eposide-(25000): [3300/5000]	Time 0.410 (0.431)	Data 0.000 (0.001)	Loss 1.616 (1.601)	Prec@1 22.667 (26.136)
Eposide-(25000): [3400/5000]	Time 0.424 (0.431)	Data 0.000 (0.001)	Loss 1.555 (1.600)	Prec@1 30.667 (26.163)
Eposide-(25000): [3500/5000]	Time 0.447 (0.431)	Data 0.000 (0.001)	Loss 1.607 (1.599)	Prec@1 25.333 (26.185)
Eposide-(25000): [3600/5000]	Time 0.436 (0.431)	Data 0.000 (0.000)	Loss 1.566 (1.598)	Prec@1 24.000 (26.207)
Eposide-(25000): [3700/5000]	Time 0.419 (0.431)	Data 0.000 (0.000)	Loss 1.586 (1.598)	Prec@1 22.667 (26.233)
Eposide-(25000): [3800/5000]	Time 0.450 (0.431)	Data 0.001 (0.000)	Loss 1.564 (1.597)	Prec@1 22.667 (26.237)
Eposide-(25000): [3900/5000]	Time 0.441 (0.431)	Data 0.000 (0.000)	Loss 1.613 (1.596)	Prec@1 30.667 (26.263)
Eposide-(25000): [4000/5000]	Time 0.453 (0.432)	Data 0.000 (0.000)	Loss 1.646 (1.595)	Prec@1 24.000 (26.258)
Eposide-(25000): [4100/5000]	Time 0.433 (0.432)	Data 0.000 (0.000)	Loss 1.629 (1.595)	Prec@1 20.000 (26.262)
Eposide-(25000): [4200/5000]	Time 0.436 (0.432)	Data 0.000 (0.000)	Loss 1.617 (1.595)	Prec@1 28.000 (26.270)
Eposide-(25000): [4300/5000]	Time 0.434 (0.432)	Data 0.000 (0.000)	Loss 1.558 (1.594)	Prec@1 18.667 (26.282)
Eposide-(25000): [4400/5000]	Time 0.437 (0.432)	Data 0.000 (0.000)	Loss 1.639 (1.593)	Prec@1 20.000 (26.314)
Eposide-(25000): [4500/5000]	Time 0.448 (0.432)	Data 0.000 (0.000)	Loss 1.552 (1.593)	Prec@1 30.667 (26.319)
Eposide-(25000): [4600/5000]	Time 0.423 (0.432)	Data 0.000 (0.000)	Loss 1.588 (1.592)	Prec@1 21.333 (26.325)
Eposide-(25000): [4700/5000]	Time 0.412 (0.432)	Data 0.000 (0.000)	Loss 1.565 (1.592)	Prec@1 26.667 (26.337)
Eposide-(25000): [4800/5000]	Time 0.476 (0.432)	Data 0.000 (0.000)	Loss 1.525 (1.591)	Prec@1 28.000 (26.343)
Eposide-(25000): [4900/5000]	Time 0.417 (0.432)	Data 0.000 (0.000)	Loss 1.483 (1.590)	Prec@1 38.667 (26.393)
============ validation on the val set ============
Test-(5): [100/500]	Time 0.276 (0.280)	Loss 1.864 (1.719)	Prec@1 21.333 (23.538)
Test-(5): [200/500]	Time 0.265 (0.274)	Loss 1.635 (1.703)	Prec@1 20.000 (23.310)
Test-(5): [300/500]	Time 0.247 (0.273)	Loss 1.603 (1.687)	Prec@1 30.667 (23.446)
Test-(5): [400/500]	Time 0.277 (0.271)	Loss 1.632 (1.686)	Prec@1 25.333 (23.445)
 * Prec@1 23.365 Best_prec1 22.267
============ Testing on the test set ============
Test-(5): [100/500]	Time 0.253 (0.278)	Loss 1.670 (1.652)	Prec@1 20.000 (21.320)
Test-(5): [200/500]	Time 0.270 (0.274)	Loss 1.720 (1.652)	Prec@1 20.000 (21.121)
Test-(5): [300/500]	Time 0.258 (0.272)	Loss 1.656 (1.652)	Prec@1 20.000 (21.090)
Test-(5): [400/500]	Time 0.257 (0.271)	Loss 1.676 (1.652)	Prec@1 20.000 (21.047)
 * Prec@1 21.037 Best_prec1 23.365
===================================== Epoch 6 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(30000): [100/5000]	Time 0.437 (0.443)	Data 0.000 (0.011)	Loss 1.593 (1.567)	Prec@1 28.000 (26.469)
Eposide-(30000): [200/5000]	Time 0.432 (0.436)	Data 0.000 (0.006)	Loss 1.630 (1.562)	Prec@1 24.000 (27.231)
Eposide-(30000): [300/5000]	Time 0.412 (0.436)	Data 0.000 (0.004)	Loss 1.605 (1.558)	Prec@1 22.667 (27.522)
Eposide-(30000): [400/5000]	Time 0.428 (0.435)	Data 0.000 (0.003)	Loss 1.574 (1.564)	Prec@1 25.333 (27.175)
Eposide-(30000): [500/5000]	Time 0.434 (0.433)	Data 0.000 (0.002)	Loss 1.476 (1.566)	Prec@1 36.000 (26.917)
Eposide-(30000): [600/5000]	Time 0.432 (0.433)	Data 0.000 (0.002)	Loss 1.604 (1.566)	Prec@1 24.000 (26.804)
Eposide-(30000): [700/5000]	Time 0.432 (0.432)	Data 0.000 (0.002)	Loss 1.521 (1.566)	Prec@1 32.000 (26.813)
Eposide-(30000): [800/5000]	Time 0.426 (0.431)	Data 0.000 (0.002)	Loss 1.655 (1.565)	Prec@1 28.000 (26.971)
Eposide-(30000): [900/5000]	Time 0.444 (0.431)	Data 0.000 (0.001)	Loss 1.645 (1.566)	Prec@1 21.333 (26.920)
Eposide-(30000): [1000/5000]	Time 0.431 (0.431)	Data 0.000 (0.001)	Loss 1.633 (1.567)	Prec@1 26.667 (26.957)
Eposide-(30000): [1100/5000]	Time 0.409 (0.431)	Data 0.000 (0.001)	Loss 1.592 (1.568)	Prec@1 20.000 (26.865)
Eposide-(30000): [1200/5000]	Time 0.435 (0.430)	Data 0.000 (0.001)	Loss 1.429 (1.566)	Prec@1 33.333 (27.030)
Eposide-(30000): [1300/5000]	Time 0.412 (0.430)	Data 0.000 (0.001)	Loss 1.562 (1.565)	Prec@1 30.667 (27.132)
Eposide-(30000): [1400/5000]	Time 0.432 (0.431)	Data 0.000 (0.001)	Loss 1.262 (1.565)	Prec@1 37.333 (27.106)
Eposide-(30000): [1500/5000]	Time 0.450 (0.430)	Data 0.000 (0.001)	Loss 1.576 (1.565)	Prec@1 29.333 (27.143)
Eposide-(30000): [1600/5000]	Time 0.433 (0.431)	Data 0.000 (0.001)	Loss 1.427 (1.565)	Prec@1 38.667 (27.175)
Eposide-(30000): [1700/5000]	Time 0.443 (0.431)	Data 0.000 (0.001)	Loss 1.632 (1.564)	Prec@1 24.000 (27.262)
Eposide-(30000): [1800/5000]	Time 0.425 (0.431)	Data 0.000 (0.001)	Loss 1.620 (1.564)	Prec@1 21.333 (27.243)
Eposide-(30000): [1900/5000]	Time 0.419 (0.431)	Data 0.000 (0.001)	Loss 1.576 (1.564)	Prec@1 24.000 (27.298)
Eposide-(30000): [2000/5000]	Time 0.423 (0.431)	Data 0.000 (0.001)	Loss 1.602 (1.564)	Prec@1 24.000 (27.287)
Eposide-(30000): [2100/5000]	Time 0.417 (0.431)	Data 0.000 (0.001)	Loss 1.617 (1.563)	Prec@1 20.000 (27.270)
Eposide-(30000): [2200/5000]	Time 0.446 (0.431)	Data 0.000 (0.001)	Loss 1.566 (1.563)	Prec@1 24.000 (27.279)
Eposide-(30000): [2300/5000]	Time 0.429 (0.431)	Data 0.000 (0.001)	Loss 1.577 (1.562)	Prec@1 25.333 (27.352)
Eposide-(30000): [2400/5000]	Time 0.424 (0.431)	Data 0.000 (0.001)	Loss 1.413 (1.562)	Prec@1 40.000 (27.349)
Eposide-(30000): [2500/5000]	Time 0.430 (0.431)	Data 0.000 (0.001)	Loss 1.279 (1.561)	Prec@1 40.000 (27.399)
Eposide-(30000): [2600/5000]	Time 0.437 (0.431)	Data 0.000 (0.001)	Loss 1.566 (1.561)	Prec@1 28.000 (27.448)
Eposide-(30000): [2700/5000]	Time 0.425 (0.431)	Data 0.000 (0.001)	Loss 1.513 (1.561)	Prec@1 32.000 (27.489)
Eposide-(30000): [2800/5000]	Time 0.432 (0.431)	Data 0.000 (0.001)	Loss 1.495 (1.560)	Prec@1 32.000 (27.511)
Eposide-(30000): [2900/5000]	Time 0.450 (0.431)	Data 0.000 (0.001)	Loss 1.563 (1.560)	Prec@1 33.333 (27.503)
Eposide-(30000): [3000/5000]	Time 0.444 (0.431)	Data 0.001 (0.001)	Loss 1.409 (1.560)	Prec@1 46.667 (27.525)
Eposide-(30000): [3100/5000]	Time 0.451 (0.431)	Data 0.000 (0.001)	Loss 1.441 (1.560)	Prec@1 41.333 (27.523)
Eposide-(30000): [3200/5000]	Time 0.423 (0.431)	Data 0.000 (0.001)	Loss 1.540 (1.559)	Prec@1 32.000 (27.581)
Eposide-(30000): [3300/5000]	Time 0.432 (0.432)	Data 0.000 (0.001)	Loss 1.613 (1.558)	Prec@1 21.333 (27.633)
Eposide-(30000): [3400/5000]	Time 0.410 (0.431)	Data 0.000 (0.001)	Loss 1.627 (1.558)	Prec@1 20.000 (27.617)
Eposide-(30000): [3500/5000]	Time 0.431 (0.431)	Data 0.000 (0.001)	Loss 1.609 (1.558)	Prec@1 20.000 (27.656)
Eposide-(30000): [3600/5000]	Time 0.425 (0.431)	Data 0.000 (0.001)	Loss 1.430 (1.557)	Prec@1 29.333 (27.680)
Eposide-(30000): [3700/5000]	Time 0.418 (0.431)	Data 0.000 (0.001)	Loss 1.624 (1.557)	Prec@1 20.000 (27.720)
Eposide-(30000): [3800/5000]	Time 0.423 (0.431)	Data 0.000 (0.001)	Loss 1.582 (1.557)	Prec@1 29.333 (27.739)
Eposide-(30000): [3900/5000]	Time 0.424 (0.431)	Data 0.000 (0.001)	Loss 1.578 (1.556)	Prec@1 24.000 (27.765)
Eposide-(30000): [4000/5000]	Time 0.432 (0.432)	Data 0.000 (0.001)	Loss 1.541 (1.556)	Prec@1 30.667 (27.795)
Eposide-(30000): [4100/5000]	Time 0.447 (0.432)	Data 0.000 (0.001)	Loss 1.495 (1.555)	Prec@1 32.000 (27.851)
Eposide-(30000): [4200/5000]	Time 0.423 (0.432)	Data 0.000 (0.001)	Loss 1.626 (1.555)	Prec@1 30.667 (27.860)
Eposide-(30000): [4300/5000]	Time 0.422 (0.432)	Data 0.000 (0.000)	Loss 1.556 (1.555)	Prec@1 26.667 (27.865)
Eposide-(30000): [4400/5000]	Time 0.435 (0.432)	Data 0.000 (0.000)	Loss 1.613 (1.555)	Prec@1 22.667 (27.860)
Eposide-(30000): [4500/5000]	Time 0.432 (0.432)	Data 0.000 (0.000)	Loss 1.616 (1.555)	Prec@1 25.333 (27.857)
Eposide-(30000): [4600/5000]	Time 0.428 (0.432)	Data 0.000 (0.000)	Loss 1.627 (1.554)	Prec@1 24.000 (27.870)
Eposide-(30000): [4700/5000]	Time 0.434 (0.432)	Data 0.001 (0.000)	Loss 1.599 (1.554)	Prec@1 21.333 (27.874)
Eposide-(30000): [4800/5000]	Time 0.437 (0.432)	Data 0.000 (0.000)	Loss 1.545 (1.554)	Prec@1 30.667 (27.892)
Eposide-(30000): [4900/5000]	Time 0.496 (0.432)	Data 0.000 (0.000)	Loss 1.646 (1.553)	Prec@1 26.667 (27.908)
============ validation on the val set ============
Test-(6): [100/500]	Time 0.291 (0.279)	Loss 1.540 (1.647)	Prec@1 20.000 (25.611)
Test-(6): [200/500]	Time 0.259 (0.274)	Loss 1.785 (1.649)	Prec@1 33.333 (25.884)
Test-(6): [300/500]	Time 0.266 (0.271)	Loss 1.595 (1.649)	Prec@1 22.667 (25.971)
Test-(6): [400/500]	Time 0.262 (0.270)	Loss 1.537 (1.654)	Prec@1 26.667 (25.938)
 * Prec@1 25.691 Best_prec1 23.365
============ Testing on the test set ============
Test-(6): [100/500]	Time 0.255 (0.283)	Loss 1.608 (1.635)	Prec@1 20.000 (22.178)
Test-(6): [200/500]	Time 0.266 (0.277)	Loss 1.641 (1.635)	Prec@1 17.333 (22.488)
Test-(6): [300/500]	Time 0.265 (0.275)	Loss 1.605 (1.639)	Prec@1 18.667 (22.357)
Test-(6): [400/500]	Time 0.295 (0.273)	Loss 1.642 (1.639)	Prec@1 21.333 (22.444)
 * Prec@1 22.416 Best_prec1 25.691
===================================== Epoch 7 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(35000): [100/5000]	Time 0.441 (0.445)	Data 0.000 (0.007)	Loss 1.574 (1.524)	Prec@1 32.000 (30.007)
Eposide-(35000): [200/5000]	Time 0.442 (0.438)	Data 0.000 (0.003)	Loss 1.634 (1.530)	Prec@1 24.000 (29.320)
Eposide-(35000): [300/5000]	Time 0.469 (0.435)	Data 0.000 (0.002)	Loss 1.629 (1.531)	Prec@1 21.333 (29.192)
Eposide-(35000): [400/5000]	Time 0.443 (0.435)	Data 0.000 (0.002)	Loss 1.435 (1.532)	Prec@1 32.000 (29.157)
Eposide-(35000): [500/5000]	Time 0.439 (0.433)	Data 0.000 (0.002)	Loss 1.458 (1.532)	Prec@1 30.667 (29.118)
Eposide-(35000): [600/5000]	Time 0.433 (0.433)	Data 0.000 (0.001)	Loss 1.622 (1.532)	Prec@1 22.667 (29.156)
Eposide-(35000): [700/5000]	Time 0.422 (0.432)	Data 0.000 (0.001)	Loss 1.591 (1.534)	Prec@1 28.000 (29.086)
Eposide-(35000): [800/5000]	Time 0.430 (0.432)	Data 0.000 (0.001)	Loss 1.498 (1.533)	Prec@1 34.667 (29.248)
Eposide-(35000): [900/5000]	Time 0.426 (0.432)	Data 0.000 (0.001)	Loss 1.594 (1.533)	Prec@1 25.333 (29.203)
Eposide-(35000): [1000/5000]	Time 0.410 (0.432)	Data 0.000 (0.001)	Loss 1.347 (1.533)	Prec@1 34.667 (29.247)
Eposide-(35000): [1100/5000]	Time 0.448 (0.432)	Data 0.000 (0.001)	Loss 1.586 (1.533)	Prec@1 17.333 (29.154)
Eposide-(35000): [1200/5000]	Time 0.425 (0.432)	Data 0.000 (0.001)	Loss 1.598 (1.535)	Prec@1 29.333 (28.995)
Eposide-(35000): [1300/5000]	Time 0.423 (0.432)	Data 0.000 (0.001)	Loss 1.630 (1.536)	Prec@1 21.333 (28.925)
Eposide-(35000): [1400/5000]	Time 0.412 (0.432)	Data 0.000 (0.001)	Loss 1.556 (1.537)	Prec@1 25.333 (28.954)
Eposide-(35000): [1500/5000]	Time 0.425 (0.432)	Data 0.001 (0.001)	Loss 1.607 (1.537)	Prec@1 21.333 (28.894)
Eposide-(35000): [1600/5000]	Time 0.425 (0.432)	Data 0.000 (0.001)	Loss 1.721 (1.537)	Prec@1 20.000 (28.866)
Eposide-(35000): [1700/5000]	Time 0.460 (0.431)	Data 0.000 (0.001)	Loss 1.589 (1.537)	Prec@1 20.000 (28.908)
Eposide-(35000): [1800/5000]	Time 0.418 (0.432)	Data 0.000 (0.001)	Loss 1.507 (1.536)	Prec@1 26.667 (28.901)
Eposide-(35000): [1900/5000]	Time 0.429 (0.431)	Data 0.000 (0.001)	Loss 1.532 (1.536)	Prec@1 26.667 (28.889)
Eposide-(35000): [2000/5000]	Time 0.418 (0.431)	Data 0.000 (0.001)	Loss 1.400 (1.535)	Prec@1 38.667 (28.942)
Eposide-(35000): [2100/5000]	Time 0.412 (0.431)	Data 0.000 (0.001)	Loss 1.602 (1.535)	Prec@1 25.333 (28.891)
Eposide-(35000): [2200/5000]	Time 0.452 (0.431)	Data 0.000 (0.001)	Loss 1.463 (1.535)	Prec@1 37.333 (28.890)
Eposide-(35000): [2300/5000]	Time 0.424 (0.432)	Data 0.000 (0.001)	Loss 1.495 (1.535)	Prec@1 25.333 (28.874)
Eposide-(35000): [2400/5000]	Time 0.467 (0.431)	Data 0.000 (0.001)	Loss 1.553 (1.535)	Prec@1 28.000 (28.865)
Eposide-(35000): [2500/5000]	Time 0.433 (0.431)	Data 0.000 (0.001)	Loss 1.590 (1.535)	Prec@1 30.667 (28.867)
Eposide-(35000): [2600/5000]	Time 0.425 (0.431)	Data 0.000 (0.000)	Loss 1.486 (1.534)	Prec@1 32.000 (28.908)
Eposide-(35000): [2700/5000]	Time 0.428 (0.431)	Data 0.000 (0.000)	Loss 1.343 (1.534)	Prec@1 38.667 (28.930)
Eposide-(35000): [2800/5000]	Time 0.413 (0.431)	Data 0.000 (0.000)	Loss 1.337 (1.533)	Prec@1 40.000 (28.919)
Eposide-(35000): [2900/5000]	Time 0.433 (0.431)	Data 0.000 (0.000)	Loss 1.627 (1.534)	Prec@1 28.000 (28.923)
Eposide-(35000): [3000/5000]	Time 0.442 (0.431)	Data 0.000 (0.000)	Loss 1.336 (1.534)	Prec@1 38.667 (28.947)
Eposide-(35000): [3100/5000]	Time 0.422 (0.431)	Data 0.000 (0.000)	Loss 1.531 (1.534)	Prec@1 22.667 (28.919)
Eposide-(35000): [3200/5000]	Time 0.409 (0.431)	Data 0.000 (0.000)	Loss 1.513 (1.534)	Prec@1 40.000 (28.897)
Eposide-(35000): [3300/5000]	Time 0.414 (0.432)	Data 0.000 (0.000)	Loss 1.621 (1.533)	Prec@1 28.000 (28.939)
Eposide-(35000): [3400/5000]	Time 0.431 (0.432)	Data 0.000 (0.000)	Loss 1.546 (1.533)	Prec@1 30.667 (28.930)
Eposide-(35000): [3500/5000]	Time 0.425 (0.431)	Data 0.000 (0.000)	Loss 1.446 (1.533)	Prec@1 30.667 (28.941)
Eposide-(35000): [3600/5000]	Time 0.414 (0.432)	Data 0.000 (0.000)	Loss 1.601 (1.533)	Prec@1 22.667 (28.938)
Eposide-(35000): [3700/5000]	Time 0.454 (0.432)	Data 0.000 (0.000)	Loss 1.593 (1.534)	Prec@1 26.667 (28.911)
Eposide-(35000): [3800/5000]	Time 0.426 (0.432)	Data 0.000 (0.000)	Loss 1.476 (1.534)	Prec@1 34.667 (28.926)
Eposide-(35000): [3900/5000]	Time 0.502 (0.432)	Data 0.000 (0.000)	Loss 1.625 (1.533)	Prec@1 22.667 (28.951)
Eposide-(35000): [4000/5000]	Time 0.444 (0.432)	Data 0.000 (0.000)	Loss 1.609 (1.533)	Prec@1 26.667 (28.981)
Eposide-(35000): [4100/5000]	Time 0.410 (0.432)	Data 0.000 (0.000)	Loss 1.684 (1.533)	Prec@1 25.333 (28.993)
Eposide-(35000): [4200/5000]	Time 0.424 (0.432)	Data 0.000 (0.000)	Loss 1.466 (1.533)	Prec@1 33.333 (28.990)
Eposide-(35000): [4300/5000]	Time 0.421 (0.432)	Data 0.000 (0.000)	Loss 1.338 (1.532)	Prec@1 37.333 (29.010)
Eposide-(35000): [4400/5000]	Time 0.414 (0.432)	Data 0.000 (0.000)	Loss 1.630 (1.532)	Prec@1 22.667 (29.022)
Eposide-(35000): [4500/5000]	Time 0.426 (0.432)	Data 0.000 (0.000)	Loss 1.587 (1.532)	Prec@1 22.667 (29.026)
Eposide-(35000): [4600/5000]	Time 0.431 (0.432)	Data 0.000 (0.000)	Loss 1.606 (1.532)	Prec@1 24.000 (29.035)
Eposide-(35000): [4700/5000]	Time 0.448 (0.432)	Data 0.000 (0.000)	Loss 1.583 (1.532)	Prec@1 29.333 (29.045)
Eposide-(35000): [4800/5000]	Time 0.428 (0.431)	Data 0.000 (0.000)	Loss 1.551 (1.532)	Prec@1 22.667 (29.051)
Eposide-(35000): [4900/5000]	Time 0.439 (0.431)	Data 0.001 (0.000)	Loss 1.482 (1.531)	Prec@1 21.333 (29.067)
============ validation on the val set ============
Test-(7): [100/500]	Time 0.255 (0.279)	Loss 1.564 (1.641)	Prec@1 29.333 (25.465)
Test-(7): [200/500]	Time 0.255 (0.273)	Loss 1.680 (1.660)	Prec@1 22.667 (25.353)
Test-(7): [300/500]	Time 0.252 (0.271)	Loss 1.865 (1.663)	Prec@1 24.000 (25.107)
Test-(7): [400/500]	Time 0.253 (0.270)	Loss 1.632 (1.662)	Prec@1 26.667 (25.064)
 * Prec@1 25.037 Best_prec1 25.691
============ Testing on the test set ============
Test-(7): [100/500]	Time 0.271 (0.278)	Loss 1.632 (1.670)	Prec@1 20.000 (22.244)
Test-(7): [200/500]	Time 0.258 (0.274)	Loss 1.613 (1.671)	Prec@1 22.667 (22.235)
Test-(7): [300/500]	Time 0.255 (0.272)	Loss 1.730 (1.667)	Prec@1 17.333 (22.374)
Test-(7): [400/500]	Time 0.374 (0.271)	Loss 1.629 (1.669)	Prec@1 28.000 (22.354)
 * Prec@1 22.347 Best_prec1 25.691
===================================== Epoch 8 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(40000): [100/5000]	Time 0.424 (0.445)	Data 0.000 (0.010)	Loss 1.290 (1.512)	Prec@1 37.333 (30.416)
Eposide-(40000): [200/5000]	Time 0.432 (0.439)	Data 0.000 (0.005)	Loss 1.604 (1.509)	Prec@1 24.000 (30.773)
Eposide-(40000): [300/5000]	Time 0.431 (0.436)	Data 0.000 (0.004)	Loss 1.561 (1.512)	Prec@1 26.667 (30.361)
Eposide-(40000): [400/5000]	Time 0.450 (0.434)	Data 0.000 (0.003)	Loss 1.623 (1.514)	Prec@1 18.667 (30.274)
Eposide-(40000): [500/5000]	Time 0.425 (0.434)	Data 0.000 (0.002)	Loss 1.321 (1.514)	Prec@1 37.333 (30.209)
Eposide-(40000): [600/5000]	Time 0.411 (0.433)	Data 0.000 (0.002)	Loss 1.455 (1.516)	Prec@1 36.000 (30.143)
Eposide-(40000): [700/5000]	Time 0.424 (0.432)	Data 0.000 (0.002)	Loss 1.465 (1.515)	Prec@1 33.333 (30.161)
Eposide-(40000): [800/5000]	Time 0.423 (0.432)	Data 0.000 (0.002)	Loss 1.587 (1.514)	Prec@1 24.000 (30.277)
Eposide-(40000): [900/5000]	Time 0.463 (0.432)	Data 0.000 (0.001)	Loss 1.604 (1.516)	Prec@1 24.000 (30.174)
Eposide-(40000): [1000/5000]	Time 0.577 (0.432)	Data 0.000 (0.001)	Loss 1.635 (1.517)	Prec@1 22.667 (30.091)
Eposide-(40000): [1100/5000]	Time 0.435 (0.432)	Data 0.000 (0.001)	Loss 1.667 (1.517)	Prec@1 26.667 (30.071)
Eposide-(40000): [1200/5000]	Time 0.408 (0.432)	Data 0.000 (0.001)	Loss 1.622 (1.517)	Prec@1 21.333 (29.988)
Eposide-(40000): [1300/5000]	Time 0.407 (0.431)	Data 0.000 (0.001)	Loss 1.320 (1.518)	Prec@1 44.000 (29.993)
Eposide-(40000): [1400/5000]	Time 0.428 (0.432)	Data 0.000 (0.001)	Loss 1.524 (1.518)	Prec@1 32.000 (29.950)
Eposide-(40000): [1500/5000]	Time 0.445 (0.432)	Data 0.000 (0.001)	Loss 1.580 (1.519)	Prec@1 21.333 (29.892)
Eposide-(40000): [1600/5000]	Time 0.408 (0.432)	Data 0.000 (0.001)	Loss 1.451 (1.519)	Prec@1 28.000 (29.954)
Eposide-(40000): [1700/5000]	Time 0.448 (0.431)	Data 0.000 (0.001)	Loss 1.479 (1.519)	Prec@1 26.667 (29.909)
Eposide-(40000): [1800/5000]	Time 0.529 (0.432)	Data 0.000 (0.001)	Loss 1.582 (1.520)	Prec@1 26.667 (29.846)
Eposide-(40000): [1900/5000]	Time 0.420 (0.432)	Data 0.000 (0.001)	Loss 1.404 (1.520)	Prec@1 29.333 (29.793)
Eposide-(40000): [2000/5000]	Time 0.445 (0.432)	Data 0.000 (0.001)	Loss 1.551 (1.520)	Prec@1 25.333 (29.803)
Eposide-(40000): [2100/5000]	Time 0.539 (0.432)	Data 0.000 (0.001)	Loss 1.662 (1.521)	Prec@1 21.333 (29.731)
Eposide-(40000): [2200/5000]	Time 0.432 (0.432)	Data 0.000 (0.001)	Loss 1.509 (1.521)	Prec@1 34.667 (29.731)
Eposide-(40000): [2300/5000]	Time 0.412 (0.432)	Data 0.000 (0.001)	Loss 1.574 (1.522)	Prec@1 32.000 (29.725)
Eposide-(40000): [2400/5000]	Time 0.432 (0.432)	Data 0.000 (0.001)	Loss 1.283 (1.522)	Prec@1 36.000 (29.730)
Eposide-(40000): [2500/5000]	Time 0.427 (0.432)	Data 0.001 (0.001)	Loss 1.378 (1.522)	Prec@1 38.667 (29.762)
Eposide-(40000): [2600/5000]	Time 0.444 (0.432)	Data 0.000 (0.001)	Loss 1.453 (1.521)	Prec@1 34.667 (29.810)
Eposide-(40000): [2700/5000]	Time 0.425 (0.432)	Data 0.000 (0.001)	Loss 1.340 (1.520)	Prec@1 38.667 (29.872)
Eposide-(40000): [2800/5000]	Time 0.439 (0.432)	Data 0.000 (0.001)	Loss 1.445 (1.520)	Prec@1 37.333 (29.860)
Eposide-(40000): [2900/5000]	Time 0.423 (0.432)	Data 0.000 (0.001)	Loss 1.572 (1.520)	Prec@1 29.333 (29.874)
Eposide-(40000): [3000/5000]	Time 0.428 (0.432)	Data 0.001 (0.001)	Loss 1.617 (1.520)	Prec@1 22.667 (29.867)
Eposide-(40000): [3100/5000]	Time 0.427 (0.432)	Data 0.000 (0.001)	Loss 1.304 (1.519)	Prec@1 37.333 (29.855)
Eposide-(40000): [3200/5000]	Time 0.552 (0.432)	Data 0.000 (0.001)	Loss 1.375 (1.519)	Prec@1 34.667 (29.868)
Eposide-(40000): [3300/5000]	Time 0.436 (0.432)	Data 0.000 (0.001)	Loss 1.580 (1.519)	Prec@1 22.667 (29.854)
Eposide-(40000): [3400/5000]	Time 0.427 (0.432)	Data 0.000 (0.001)	Loss 1.553 (1.519)	Prec@1 28.000 (29.845)
Eposide-(40000): [3500/5000]	Time 0.430 (0.432)	Data 0.000 (0.001)	Loss 1.252 (1.519)	Prec@1 45.333 (29.857)
Eposide-(40000): [3600/5000]	Time 0.409 (0.432)	Data 0.000 (0.001)	Loss 1.366 (1.519)	Prec@1 34.667 (29.862)
Eposide-(40000): [3700/5000]	Time 0.439 (0.432)	Data 0.000 (0.001)	Loss 1.445 (1.519)	Prec@1 40.000 (29.860)
Eposide-(40000): [3800/5000]	Time 0.414 (0.432)	Data 0.000 (0.000)	Loss 1.337 (1.519)	Prec@1 36.000 (29.875)
Eposide-(40000): [3900/5000]	Time 0.430 (0.432)	Data 0.000 (0.000)	Loss 1.586 (1.518)	Prec@1 24.000 (29.900)
Eposide-(40000): [4000/5000]	Time 0.411 (0.432)	Data 0.000 (0.000)	Loss 1.570 (1.518)	Prec@1 26.667 (29.896)
Eposide-(40000): [4100/5000]	Time 0.435 (0.432)	Data 0.000 (0.000)	Loss 1.381 (1.517)	Prec@1 33.333 (29.920)
Eposide-(40000): [4200/5000]	Time 0.414 (0.432)	Data 0.000 (0.000)	Loss 1.598 (1.517)	Prec@1 30.667 (29.906)
Eposide-(40000): [4300/5000]	Time 0.431 (0.432)	Data 0.000 (0.000)	Loss 1.307 (1.517)	Prec@1 46.667 (29.907)
Eposide-(40000): [4400/5000]	Time 0.432 (0.432)	Data 0.000 (0.000)	Loss 1.351 (1.517)	Prec@1 33.333 (29.900)
Eposide-(40000): [4500/5000]	Time 0.414 (0.432)	Data 0.000 (0.000)	Loss 1.492 (1.517)	Prec@1 36.000 (29.893)
Eposide-(40000): [4600/5000]	Time 0.427 (0.432)	Data 0.000 (0.000)	Loss 1.519 (1.518)	Prec@1 29.333 (29.900)
Eposide-(40000): [4700/5000]	Time 0.430 (0.432)	Data 0.000 (0.000)	Loss 1.349 (1.517)	Prec@1 38.667 (29.895)
Eposide-(40000): [4800/5000]	Time 0.432 (0.432)	Data 0.000 (0.000)	Loss 1.565 (1.518)	Prec@1 28.000 (29.873)
Eposide-(40000): [4900/5000]	Time 0.407 (0.432)	Data 0.000 (0.000)	Loss 1.325 (1.518)	Prec@1 45.333 (29.859)
============ validation on the val set ============
Test-(8): [100/500]	Time 0.260 (0.276)	Loss 1.730 (1.720)	Prec@1 21.333 (25.347)
Test-(8): [200/500]	Time 0.256 (0.272)	Loss 2.073 (1.703)	Prec@1 25.333 (25.340)
Test-(8): [300/500]	Time 0.270 (0.270)	Loss 2.358 (1.707)	Prec@1 20.000 (25.488)
Test-(8): [400/500]	Time 0.268 (0.270)	Loss 1.766 (1.711)	Prec@1 28.000 (25.416)
 * Prec@1 25.509 Best_prec1 25.691
============ Testing on the test set ============
Test-(8): [100/500]	Time 0.289 (0.279)	Loss 1.629 (1.669)	Prec@1 21.333 (22.865)
Test-(8): [200/500]	Time 0.258 (0.274)	Loss 1.625 (1.678)	Prec@1 28.000 (22.640)
Test-(8): [300/500]	Time 0.257 (0.272)	Loss 1.623 (1.681)	Prec@1 20.000 (22.583)
Test-(8): [400/500]	Time 0.360 (0.271)	Loss 1.787 (1.680)	Prec@1 24.000 (22.680)
 * Prec@1 22.725 Best_prec1 25.691
===================================== Epoch 9 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(45000): [100/5000]	Time 0.422 (0.447)	Data 0.000 (0.006)	Loss 1.528 (1.506)	Prec@1 34.667 (30.957)
Eposide-(45000): [200/5000]	Time 0.536 (0.440)	Data 0.000 (0.003)	Loss 1.260 (1.505)	Prec@1 32.000 (30.448)
Eposide-(45000): [300/5000]	Time 0.424 (0.438)	Data 0.000 (0.002)	Loss 1.521 (1.506)	Prec@1 32.000 (30.618)
Eposide-(45000): [400/5000]	Time 0.421 (0.437)	Data 0.000 (0.002)	Loss 1.452 (1.508)	Prec@1 37.333 (30.607)
Eposide-(45000): [500/5000]	Time 0.422 (0.436)	Data 0.000 (0.001)	Loss 1.421 (1.507)	Prec@1 38.667 (30.531)
Eposide-(45000): [600/5000]	Time 0.426 (0.435)	Data 0.000 (0.001)	Loss 1.408 (1.507)	Prec@1 34.667 (30.558)
Eposide-(45000): [700/5000]	Time 0.474 (0.435)	Data 0.000 (0.001)	Loss 1.474 (1.507)	Prec@1 32.000 (30.779)
Eposide-(45000): [800/5000]	Time 0.424 (0.434)	Data 0.000 (0.001)	Loss 1.591 (1.506)	Prec@1 25.333 (30.803)
Eposide-(45000): [900/5000]	Time 0.434 (0.434)	Data 0.000 (0.001)	Loss 1.534 (1.507)	Prec@1 32.000 (30.713)
Eposide-(45000): [1000/5000]	Time 0.428 (0.433)	Data 0.000 (0.001)	Loss 1.271 (1.507)	Prec@1 40.000 (30.643)
Eposide-(45000): [1100/5000]	Time 0.422 (0.433)	Data 0.000 (0.001)	Loss 1.441 (1.508)	Prec@1 37.333 (30.569)
Eposide-(45000): [1200/5000]	Time 0.439 (0.433)	Data 0.001 (0.001)	Loss 1.609 (1.508)	Prec@1 21.333 (30.589)
Eposide-(45000): [1300/5000]	Time 0.421 (0.433)	Data 0.000 (0.001)	Loss 1.357 (1.509)	Prec@1 36.000 (30.545)
Eposide-(45000): [1400/5000]	Time 0.415 (0.432)	Data 0.000 (0.001)	Loss 1.560 (1.508)	Prec@1 24.000 (30.547)
Eposide-(45000): [1500/5000]	Time 0.428 (0.432)	Data 0.000 (0.001)	Loss 1.456 (1.509)	Prec@1 34.667 (30.567)
Eposide-(45000): [1600/5000]	Time 0.433 (0.431)	Data 0.000 (0.001)	Loss 1.592 (1.509)	Prec@1 28.000 (30.530)
Eposide-(45000): [1700/5000]	Time 0.430 (0.431)	Data 0.000 (0.001)	Loss 1.560 (1.509)	Prec@1 33.333 (30.508)
Eposide-(45000): [1800/5000]	Time 0.425 (0.431)	Data 0.000 (0.001)	Loss 1.411 (1.509)	Prec@1 40.000 (30.505)
Eposide-(45000): [1900/5000]	Time 0.415 (0.431)	Data 0.000 (0.001)	Loss 1.576 (1.510)	Prec@1 24.000 (30.428)
Eposide-(45000): [2000/5000]	Time 0.464 (0.430)	Data 0.000 (0.001)	Loss 1.368 (1.511)	Prec@1 38.667 (30.368)
Eposide-(45000): [2100/5000]	Time 0.431 (0.430)	Data 0.000 (0.001)	Loss 1.590 (1.512)	Prec@1 24.000 (30.322)
Eposide-(45000): [2200/5000]	Time 0.411 (0.430)	Data 0.000 (0.001)	Loss 1.657 (1.510)	Prec@1 20.000 (30.403)
Eposide-(45000): [2300/5000]	Time 0.445 (0.430)	Data 0.000 (0.001)	Loss 1.560 (1.510)	Prec@1 28.000 (30.388)
Eposide-(45000): [2400/5000]	Time 0.435 (0.430)	Data 0.000 (0.000)	Loss 1.432 (1.510)	Prec@1 29.333 (30.368)
Eposide-(45000): [2500/5000]	Time 0.450 (0.430)	Data 0.000 (0.000)	Loss 1.733 (1.512)	Prec@1 20.000 (30.274)
Eposide-(45000): [2600/5000]	Time 0.411 (0.430)	Data 0.000 (0.000)	Loss 1.605 (1.511)	Prec@1 22.667 (30.324)
Eposide-(45000): [2700/5000]	Time 0.426 (0.430)	Data 0.000 (0.000)	Loss 1.420 (1.510)	Prec@1 30.667 (30.362)
Eposide-(45000): [2800/5000]	Time 0.426 (0.431)	Data 0.000 (0.000)	Loss 1.454 (1.510)	Prec@1 37.333 (30.377)
Eposide-(45000): [2900/5000]	Time 0.423 (0.430)	Data 0.000 (0.000)	Loss 1.578 (1.510)	Prec@1 22.667 (30.401)
Eposide-(45000): [3000/5000]	Time 0.427 (0.431)	Data 0.000 (0.000)	Loss 1.517 (1.510)	Prec@1 30.667 (30.425)
Eposide-(45000): [3100/5000]	Time 0.446 (0.431)	Data 0.000 (0.000)	Loss 1.635 (1.510)	Prec@1 24.000 (30.440)
Eposide-(45000): [3200/5000]	Time 0.425 (0.430)	Data 0.000 (0.000)	Loss 1.237 (1.509)	Prec@1 54.667 (30.430)
Eposide-(45000): [3300/5000]	Time 0.431 (0.431)	Data 0.000 (0.000)	Loss 1.277 (1.509)	Prec@1 42.667 (30.431)
Eposide-(45000): [3400/5000]	Time 0.430 (0.431)	Data 0.000 (0.000)	Loss 1.432 (1.509)	Prec@1 38.667 (30.445)
Eposide-(45000): [3500/5000]	Time 0.440 (0.431)	Data 0.000 (0.000)	Loss 1.596 (1.508)	Prec@1 29.333 (30.465)
Eposide-(45000): [3600/5000]	Time 0.425 (0.430)	Data 0.000 (0.000)	Loss 1.240 (1.508)	Prec@1 44.000 (30.463)
Eposide-(45000): [3700/5000]	Time 0.432 (0.430)	Data 0.000 (0.000)	Loss 1.481 (1.508)	Prec@1 34.667 (30.475)
Eposide-(45000): [3800/5000]	Time 0.448 (0.430)	Data 0.000 (0.000)	Loss 1.594 (1.507)	Prec@1 20.000 (30.514)
Eposide-(45000): [3900/5000]	Time 0.548 (0.430)	Data 0.000 (0.000)	Loss 1.643 (1.507)	Prec@1 20.000 (30.516)
Eposide-(45000): [4000/5000]	Time 0.422 (0.431)	Data 0.000 (0.000)	Loss 1.600 (1.507)	Prec@1 24.000 (30.520)
Eposide-(45000): [4100/5000]	Time 0.425 (0.431)	Data 0.000 (0.000)	Loss 1.582 (1.507)	Prec@1 30.667 (30.533)
Eposide-(45000): [4200/5000]	Time 0.430 (0.431)	Data 0.000 (0.000)	Loss 1.516 (1.507)	Prec@1 40.000 (30.549)
Eposide-(45000): [4300/5000]	Time 0.424 (0.431)	Data 0.000 (0.000)	Loss 1.606 (1.507)	Prec@1 20.000 (30.538)
Eposide-(45000): [4400/5000]	Time 0.425 (0.431)	Data 0.000 (0.000)	Loss 1.634 (1.507)	Prec@1 20.000 (30.537)
Eposide-(45000): [4500/5000]	Time 0.428 (0.431)	Data 0.000 (0.000)	Loss 1.643 (1.507)	Prec@1 21.333 (30.532)
Eposide-(45000): [4600/5000]	Time 0.425 (0.431)	Data 0.000 (0.000)	Loss 1.293 (1.507)	Prec@1 36.000 (30.517)
Eposide-(45000): [4700/5000]	Time 0.428 (0.431)	Data 0.000 (0.000)	Loss 1.451 (1.506)	Prec@1 38.667 (30.534)
Eposide-(45000): [4800/5000]	Time 0.424 (0.431)	Data 0.000 (0.000)	Loss 1.626 (1.506)	Prec@1 28.000 (30.545)
Eposide-(45000): [4900/5000]	Time 0.410 (0.431)	Data 0.000 (0.000)	Loss 1.122 (1.506)	Prec@1 48.000 (30.562)
============ validation on the val set ============
Test-(9): [100/500]	Time 0.258 (0.277)	Loss 1.673 (1.613)	Prec@1 28.000 (25.901)
Test-(9): [200/500]	Time 0.256 (0.275)	Loss 1.661 (1.608)	Prec@1 18.667 (26.381)
Test-(9): [300/500]	Time 0.255 (0.273)	Loss 1.805 (1.609)	Prec@1 20.000 (26.264)
Test-(9): [400/500]	Time 0.251 (0.271)	Loss 1.563 (1.611)	Prec@1 28.000 (26.294)
 * Prec@1 26.336 Best_prec1 25.691
============ Testing on the test set ============
Test-(9): [100/500]	Time 0.266 (0.279)	Loss 1.665 (1.653)	Prec@1 24.000 (22.205)
Test-(9): [200/500]	Time 0.264 (0.272)	Loss 1.650 (1.653)	Prec@1 21.333 (21.897)
Test-(9): [300/500]	Time 0.272 (0.271)	Loss 1.657 (1.651)	Prec@1 20.000 (21.962)
Test-(9): [400/500]	Time 0.248 (0.270)	Loss 1.704 (1.649)	Prec@1 20.000 (22.118)
 * Prec@1 22.029 Best_prec1 26.336
===================================== Epoch 10 =====================================
Trainset: 5000
Valset: 500
Testset: 500
Eposide-(50000): [100/5000]	Time 0.424 (0.445)	Data 0.000 (0.010)	Loss 1.652 (1.478)	Prec@1 24.000 (31.749)
Eposide-(50000): [200/5000]	Time 0.444 (0.438)	Data 0.000 (0.005)	Loss 1.542 (1.477)	Prec@1 34.667 (32.153)
Eposide-(50000): [300/5000]	Time 0.473 (0.436)	Data 0.000 (0.003)	Loss 1.294 (1.479)	Prec@1 49.333 (31.876)
Eposide-(50000): [400/5000]	Time 0.430 (0.435)	Data 0.000 (0.003)	Loss 1.628 (1.487)	Prec@1 34.667 (31.618)
Eposide-(50000): [500/5000]	Time 0.472 (0.435)	Data 0.000 (0.002)	Loss 1.265 (1.485)	Prec@1 45.333 (31.941)
Eposide-(50000): [600/5000]	Time 0.409 (0.434)	Data 0.000 (0.002)	Loss 1.584 (1.481)	Prec@1 29.333 (32.111)
Eposide-(50000): [700/5000]	Time 0.441 (0.434)	Data 0.000 (0.002)	Loss 1.422 (1.484)	Prec@1 40.000 (31.892)
Eposide-(50000): [800/5000]	Time 0.450 (0.434)	Data 0.000 (0.001)	Loss 1.560 (1.484)	Prec@1 22.667 (31.872)
Eposide-(50000): [900/5000]	Time 0.426 (0.433)	Data 0.000 (0.001)	Loss 1.604 (1.487)	Prec@1 25.333 (31.713)
Eposide-(50000): [1000/5000]	Time 0.424 (0.433)	Data 0.000 (0.001)	Loss 1.391 (1.487)	Prec@1 30.667 (31.658)
Eposide-(50000): [1100/5000]	Time 0.564 (0.433)	Data 0.000 (0.001)	Loss 1.557 (1.488)	Prec@1 28.000 (31.615)
Eposide-(50000): [1200/5000]	Time 0.426 (0.433)	Data 0.000 (0.001)	Loss 1.411 (1.488)	Prec@1 38.667 (31.597)
Eposide-(50000): [1300/5000]	Time 0.428 (0.433)	Data 0.000 (0.001)	Loss 1.621 (1.487)	Prec@1 24.000 (31.658)
Eposide-(50000): [1400/5000]	Time 0.431 (0.432)	Data 0.000 (0.001)	Loss 1.671 (1.486)	Prec@1 20.000 (31.697)
Eposide-(50000): [1500/5000]	Time 0.430 (0.432)	Data 0.000 (0.001)	Loss 1.566 (1.487)	Prec@1 29.333 (31.619)
Eposide-(50000): [1600/5000]	Time 0.419 (0.432)	Data 0.000 (0.001)	Loss 1.477 (1.487)	Prec@1 30.667 (31.603)
Eposide-(50000): [1700/5000]	Time 0.427 (0.432)	Data 0.000 (0.001)	Loss 1.584 (1.487)	Prec@1 21.333 (31.617)
Eposide-(50000): [1800/5000]	Time 0.408 (0.432)	Data 0.000 (0.001)	Loss 1.437 (1.488)	Prec@1 40.000 (31.565)
Eposide-(50000): [1900/5000]	Time 0.429 (0.442)	Data 0.000 (0.001)	Loss 1.529 (1.488)	Prec@1 28.000 (31.509)
Eposide-(50000): [2000/5000]	Time 0.455 (0.442)	Data 0.000 (0.001)	Loss 1.421 (1.488)	Prec@1 28.000 (31.560)
Eposide-(50000): [2100/5000]	Time 0.440 (0.442)	Data 0.000 (0.001)	Loss 1.493 (1.488)	Prec@1 36.000 (31.554)
Eposide-(50000): [2200/5000]	Time 0.421 (0.442)	Data 0.000 (0.001)	Loss 1.378 (1.488)	Prec@1 34.667 (31.584)
Eposide-(50000): [2300/5000]	Time 0.430 (0.441)	Data 0.000 (0.001)	Loss 1.548 (1.488)	Prec@1 32.000 (31.572)
Eposide-(50000): [2400/5000]	Time 0.488 (0.441)	Data 0.000 (0.001)	Loss 1.542 (1.488)	Prec@1 36.000 (31.534)
Eposide-(50000): [2500/5000]	Time 0.445 (0.442)	Data 0.000 (0.001)	Loss 1.408 (1.489)	Prec@1 37.333 (31.526)
Eposide-(50000): [2600/5000]	Time 0.430 (0.442)	Data 0.000 (0.001)	Loss 1.407 (1.489)	Prec@1 34.667 (31.505)
Eposide-(50000): [2700/5000]	Time 0.442 (0.443)	Data 0.000 (0.001)	Loss 1.368 (1.489)	Prec@1 49.333 (31.543)
Eposide-(50000): [2800/5000]	Time 0.417 (0.443)	Data 0.000 (0.001)	Loss 1.478 (1.489)	Prec@1 28.000 (31.510)
Eposide-(50000): [2900/5000]	Time 0.441 (0.443)	Data 0.000 (0.001)	Loss 1.593 (1.489)	Prec@1 26.667 (31.498)
Eposide-(50000): [3000/5000]	Time 0.418 (0.443)	Data 0.000 (0.001)	Loss 1.419 (1.489)	Prec@1 30.667 (31.505)
Eposide-(50000): [3100/5000]	Time 0.409 (0.442)	Data 0.000 (0.001)	Loss 1.460 (1.489)	Prec@1 32.000 (31.554)
Eposide-(50000): [3200/5000]	Time 0.429 (0.442)	Data 0.000 (0.001)	Loss 1.607 (1.489)	Prec@1 24.000 (31.517)
Eposide-(50000): [3300/5000]	Time 0.407 (0.442)	Data 0.000 (0.001)	Loss 1.586 (1.490)	Prec@1 29.333 (31.479)
Eposide-(50000): [3400/5000]	Time 0.450 (0.442)	Data 0.000 (0.001)	Loss 1.465 (1.490)	Prec@1 40.000 (31.468)
Eposide-(50000): [3500/5000]	Time 0.477 (0.442)	Data 0.000 (0.001)	Loss 1.625 (1.490)	Prec@1 26.667 (31.481)
Eposide-(50000): [3600/5000]	Time 0.543 (0.442)	Data 0.000 (0.001)	Loss 1.526 (1.490)	Prec@1 32.000 (31.468)
Eposide-(50000): [3700/5000]	Time 0.475 (0.442)	Data 0.000 (0.000)	Loss 1.552 (1.490)	Prec@1 30.667 (31.451)
Eposide-(50000): [3800/5000]	Time 0.432 (0.442)	Data 0.000 (0.000)	Loss 1.584 (1.491)	Prec@1 24.000 (31.434)
Eposide-(50000): [3900/5000]	Time 0.416 (0.442)	Data 0.000 (0.000)	Loss 1.460 (1.491)	Prec@1 34.667 (31.405)
Eposide-(50000): [4000/5000]	Time 0.424 (0.441)	Data 0.000 (0.000)	Loss 1.448 (1.491)	Prec@1 33.333 (31.391)
Eposide-(50000): [4100/5000]	Time 0.533 (0.441)	Data 0.000 (0.000)	Loss 1.457 (1.491)	Prec@1 40.000 (31.418)
Eposide-(50000): [4200/5000]	Time 0.424 (0.441)	Data 0.000 (0.000)	Loss 1.539 (1.491)	Prec@1 37.333 (31.433)
Eposide-(50000): [4300/5000]	Time 0.434 (0.441)	Data 0.000 (0.000)	Loss 1.536 (1.491)	Prec@1 28.000 (31.433)
Eposide-(50000): [4400/5000]	Time 0.442 (0.441)	Data 0.000 (0.000)	Loss 1.419 (1.491)	Prec@1 33.333 (31.456)
Eposide-(50000): [4500/5000]	Time 0.431 (0.440)	Data 0.000 (0.000)	Loss 1.413 (1.491)	Prec@1 34.667 (31.455)
Eposide-(50000): [4600/5000]	Time 0.438 (0.440)	Data 0.000 (0.000)	Loss 1.431 (1.491)	Prec@1 48.000 (31.452)
Eposide-(50000): [4700/5000]	Time 0.436 (0.440)	Data 0.000 (0.000)	Loss 1.454 (1.491)	Prec@1 26.667 (31.466)
Eposide-(50000): [4800/5000]	Time 0.460 (0.440)	Data 0.000 (0.000)	Loss 1.439 (1.491)	Prec@1 36.000 (31.474)
Eposide-(50000): [4900/5000]	Time 0.466 (0.440)	Data 0.000 (0.000)	Loss 1.381 (1.491)	Prec@1 44.000 (31.495)
============ validation on the val set ============
Test-(10): [100/500]	Time 0.277 (0.283)	Loss 1.568 (1.612)	Prec@1 24.000 (27.842)
Test-(10): [200/500]	Time 0.265 (0.279)	Loss 1.695 (1.614)	Prec@1 17.333 (27.376)
Test-(10): [300/500]	Time 0.265 (0.278)	Loss 1.689 (1.614)	Prec@1 24.000 (27.105)
Test-(10): [400/500]	Time 0.296 (0.282)	Loss 1.609 (1.616)	Prec@1 25.333 (27.152)
 * Prec@1 27.229 Best_prec1 26.336
============ Testing on the test set ============
Test-(10): [100/500]	Time 0.270 (0.286)	Loss 1.639 (1.671)	Prec@1 22.667 (23.036)
